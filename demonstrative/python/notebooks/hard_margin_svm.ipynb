{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook contains **hard-margin svm** manual solution using lagrangian dual as well as **Perceptron Algorithm** implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -m ipy_startup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn Solution\n",
    "\n",
    "To SVM hard margin problem\n",
    "\n",
    "Visualizing hyperplane: http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1, -1],\n",
       "        [ 0,  1],\n",
       "        [ 1, -2],\n",
       "        [ 1,  2]]), array([-1,  1, -1,  1]))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [\n",
    "    [-1, -1],\n",
    "    [0, 1],\n",
    "    [1, -2],\n",
    "    [1, 2]\n",
    "]\n",
    "y = [-1, 1, -1, 1]\n",
    "X, y = np.array(X), np.array(y)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=inf, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=1, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=False,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = SVC(kernel='linear', degree=1, C=np.inf, shrinking=False)\n",
    "m.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.2]), array([[ 0.4,  0.8]]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are values of parameters for weight vector that is normal\n",
    "# to separating hyperplane (i.e. a line in 2D)\n",
    "m.intercept_, m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4,  0.4]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Presmuably these are all the non-zero lagrange multipliers though\n",
    "# I'm not sure why they're ever negative\n",
    "m.dual_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obvious \n",
    "m.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# w = clf.coef_[0]\n",
    "# a = -w[0] / w[1]\n",
    "# xx = np.linspace(-5, 5)\n",
    "# yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "\n",
    "# To get the separating line, you first have to find an equation for the line\n",
    "# normal to the weight vector w (which has slope equal to negative reciprocal)\n",
    "w = m.coef_[0]\n",
    "s = -w[0]/w[1]\n",
    "b = - m.intercept_[0] / w[1]\n",
    "xl = np.linspace(-2, 2, num=100)\n",
    "yl = s * xl + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.49999999999999994, -0.24999999999999989)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1] dist =  [-1.11803399]\n",
      "[0 1] dist =  [ 1.11803399]\n",
      "[ 1 -2] dist =  [-1.11803399]\n",
      "[1 2] dist =  [ 2.45967478]\n"
     ]
    }
   ],
   "source": [
    "# ax + by + c = 0\n",
    "# => a =-s, b=1, c=-b\n",
    "def get_dist(slope, intercept, p):\n",
    "    \"\"\" Find smallest distance from `p` to line given by `slope` and `intercept`\"\"\"\n",
    "    return (-slope*p[0] + p[1] - intercept) / np.sqrt(slope**2 + 1)\n",
    "\n",
    "for p in X:\n",
    "    print(p, 'dist = ', get_dist(s, b, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFkCAYAAAC9wjgoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X10XXWd7/HPNwkPUxAU6BMOBYSLlOtolUFWUERpaZkO\nHAvetjzMoOkM8tDOjEVS78g4qbKESbmWcdqiLKnlSQ6lFxvwzgV6aQszpQ4gUajaCEhpWIiVVlcL\nnII9J7/7x0loHk6Ss3/J3vvsvd+vtc6i2Tkn+3s+2Um+7P37/bY55wQAALKrLu4CAABAvGgGAADI\nOJoBAAAyjmYAAICMoxkAACDjaAYAAMg4mgEAADKOZgAAgIyjGQAAIONoBgAAyLhQmwEzu9LMnjWz\n3d2PzWZ2bpj7BAAAwViY9yYws7+UVJL0giST9AVJzZKmOOe2hrZjAABQtVCbgYo7NNsl6Vrn3KpI\ndwwAACpqiGpHZlYnaY6kMZJ+HNV+AQDA0EJvBszsQyr/8T9Y0huSLnDOdQzy3CMlzZD0sqS3w64N\nAIAUOVjScZIecc7tCvLC0C8TmFmDpEmSDpf0PyRdLulTlRoCM7tE0g9CLQgAgHS71Dl3T5AXhH5m\nwDlXlPRS94c/NbOPS/oHSVdVePrLknT33Xdr8uTJYZeWKgsXLtTNN98cdxmJQmZ+yC04MvNDbsFs\n3bpVf/VXfyV1/y0NIrIxA73USTpokM+9LUmTJ0/Wxz72segqSoHDDz+czAIiMz/kFhyZ+SE3b4Ev\ns4faDJjZDZIektQp6T2SLpV0lqTpYe43i37729/GXULikJkfcguOzPyQW3TCPjMwTtIdkiZK2i3p\nOUnTnXMbQt5v5rz66qtxl5A4ZOaH3IIjMz/kFp1QmwHn3N+G+fWx36mnnhp3CYlDZn7ILTgy80Nu\n0eHeBClx8cUXx11C4pCZH3ILjsz8kFt0Il+BcChm9jFJzzzzzDMMGgEAIID29vaesymnOufag7yW\nMwMAAGQczUBKNDU1xV1C4pCZH3ILjsz8kFt0aAZSYvp0ZmsGRWZ+yC04MvNDbtFhzAAAACnAmAEA\nAOCNZgAAgIyjGUiJTZs2xV1C4pCZH3ILjsz8kFt0aAZSYsmSJXGXkDhk5ofcgiMzP+QWHQYQpkSh\nUNCYMWPiLiNRyMwPuQVHZn7ILRgGEIIfGA9k5ofcgiMzP+QWHZoBAAAyjmYAAICMoxlIiebm5rhL\nSBwy80NuwZGZH3KLDs1ASkyaNCnuEhKHzPyQW3Bk5ofcosNsAgAAUoDZBAAAwBvNAAAAGUczkBId\nHR1xl5A4ZOaH3IIjMz/kFh2agZRYtGhR3CUkDpn5IbfgyMwPuUWHZiAlli9fHncJiUNmfsgtODLz\nQ27RoRlICabgBEdmfsgtODLzQ27RoRkAACDjaAYAAMg4moGUaG1tjbuExCEzP+QWHJn5Ibfo0Ayk\nRKFQiLuExCEzP+QWHJn5IbfosBwxAAApwHLEAADAG80AAAAZRzOQEjt37oy7hMQhMz/kFhyZ+SG3\n6NAMpMS8efPiLiFxyMwPuQVHZn7ILTo0AymxePHiuEtIHDLzQ27BkZkfcosOzUBKMPsiODLzQ27B\nkZkfcosOzQAAABlHMwAAQMbRDKTEypUr4y4hccjMD7kFR2Z+yC06NAMp0d4eaLEpiMx8kVtwZOaH\n3KLDcsQAEII9e/bo/vvvV2dnp7q6unT00Ufrwgsv1NixY+MuDSk1kuWIG8IpCQCyqbOzUzfccIPu\nuuMOvf3OO3pPQ4NM0hvFov5uwQLNnTtXX73uOk2ePDnuUoF30QwAwChpb2/XjHPO0R/37NFpxaJO\nlXTYvn2SpLck/axY1P9dvVpta9eq7cEHNXXq1FjrBXqEOmbAzP7RzJ4ysz1mtsPM1prZSWHuEwDi\n8PLLL2v6tGk6ePduXVEs6jOSDuv1+UMkfULSFcWiJuzdq9x553FNHDUj7AGEZ0paJul0SdMkHSBp\nnZn9Scj7zZxcLhd3CYlDZn7IrbLFLS0qvvGGLi6VdEi/z93T698HSZrjnA7bt0+Lrr02wgqTh2Mt\nOqE2A865mc65u5xzW51zWyR9QdIkSaeGud8sWrBgQdwlJA6Z+SG3gXbt2qV8Pq/TisUBjYAkfbzf\nxwdKaiyVtH7jRv3qV7+KoMJk4liLTtRTC98ryUn6fcT7Tb3p06fHXULikJkfchvo3nvvVVeppI8O\n8vkTK2w7RdKhDQ1atWpViJUlG8dadCJrBszMJP2rpE3OuV9GtV8ACNu2bdt0RH19xbMCgzlA0riu\nLm3fvj2ssoCqRXlm4BaVm+GLhnvizJkzlcvl+jwaGxvV1tbW53nr1q2reE1p/vz5A1auam9vVy6X\nG3B/7JaWFrW2tvbZ1tnZqVwup46Ojj7bly1bpubm5j7bCoWCcrmcNm3a1Gd7Pp9XU1PTgNrmzp3L\n++B98D5S9j6KxaKs1/Y1krb2q/dF9R07IEnmnJ5++umaeR/9JfX7kYX3kc/n3/3bOGHCBOVyOS1c\nuHDAa6oVyaJDZrZc0vmSznTOdQ7xPBYd8tTW1qZZs2bFXUaikJkfchvoxhtv1De+9jV9uVTSARU+\nv1VS/1UFuiStaGjQ3C9+UStWrAi/yATiWAtmJIsOhX5moLsR+KykzwzVCGBk8vl83CUkDpn5IbeB\n5syZo7dLJf1ikM//vMK2bZJ2FYu66KJhT5ZmFsdadEI9M2Bmt0i6WFJO0vO9PrXbOfd2hedzZgBA\nIp07fbq2bNigvymVVD/Mc52ke8x0wAc/qJ//8pcqD6kCRqaWzwxcqfK6G49J+k2vx5yQ9wsAkfrn\nxYv1O0kPSioN8Twn6VFJLzin67/5TRoB1ISw1xmoc87VV3jcGeZ+ASBqZ5xxhu648079vK5Od5np\nBZXHBfRwkrZLulfSE5KWLl2qCy+8MI5SgQG4NwEAjJJLLrlE48aN0zVf+pJ+8Itf6MiGBo3tnmnw\n+4YG7SgWdcLxx+u+1lbNnj077nKBd0W96BBCUmkaCoZGZn7IbWjTpk3Ts1u2aPPmzfrcvHk6dsYM\n7Z44UedeeqnWrVun5198kUagShxr0eHMQEqwUldwZOaH3IZnZmpsbFRjY6Ok8qj4iy++OOaqkodj\nLTqRrDNQLWYTAADgp5ZnEwAAgBpHMwAAQMbRDKRE/7WtMTwy80NuwZGZH3KLDs1ASixZsiTuEhKH\nzPyQW3Bk5ofcosMAwpQoFAoaM2ZM3GUkCpn5IbfgyMwPuQXDAELwA+OBzPyQW3Bk5ofcokMzAABA\nxtEMAACQcTQDKdHc3Bx3CYlDZn7ILTgy80Nu0aEZSIlJkybFXULikJkfcguOzPyQW3SYTQAAQAow\nmwAAAHijGQAAIONoBlKio6Mj7hISh8z8kFtwZOaH3KJDM5ASixYtiruExCEzP+QWHJn5Ibfo0Ayk\nxPLly+MuIXHIzA+5BUdmfsgtOjQDKcEUnODIzA+5BUdmfsgtOjQDAABkHM0AAAAZRzOQEq2trXGX\nkDhk5ofcgiMzP+QWHZqBlCgUCnGXkDhk5ofcgiMzP+QWHZYjBgAgBViOGAAAeKMZAAAg42gGUmLn\nzp1xl5A4ZOaH3IIjMz/kFh2agZSYN29e3CUkDpn5IbfgyMwPuUWHZiAlFi9eHHcJiUNmfsgtODLz\nQ27RoRlICWZfBEdmfsgtODLzQ27RoRkAACDjaAYAAMg4moGUWLlyZdwlJA6Z+SG34MjMD7lFh2Yg\nJdrbAy02BZGZL3ILjsz8kFt0WI4YAIAUYDliAADgjWYAwJB+/etfq7m5WadOmaITjz9eU/7sz3T1\n1Vdry5YtcZcGYJQ0xF0AgNr0+uuva15Tk/7Pv/+7Dqmv138rlTRO0juS7uno0He+8x198hOf0F13\n363jjjsu5moBjESoZwbM7Ewze9DMXjWzLjPLhbm/LMvliDYoMhvcjh071Hj66Xr84Yf1WUlfKpU0\nS9IMSW9K+vtiUXMkbX3ySZ1+2ml6/vnnY6231nGs+SG36IR9meAQST+TdLWk2hmpmEILFiyIu4TE\nIbPKnHPKnXeeXn/lFTWVSvqopAN6ff7jkuolnSKpqViU/vAHnTt9uvbu3RtLvUnAseaH3KITajPg\nnHvYOffPzrkHJFmY+8q66dOnx11C4pBZZRs2bNBTP/mJZhWLOqLC50/s9e9DJc0ulbRt+3atWbMm\nogqTh2PND7lFhwGEAPpYsXy5xjc06Pgqnz9W0ol1dVr27W+HWRaAENEMAHhXqVTSj370I32kWAx0\nKm9KV5d+0t6u1157LbTaAISHZiAl2tra4i4hcchsoD179qhYKunwIZ6ztcK2nufv2rUrhKqSj2PN\nD7lFpyabgZkzZyqXy/V5NDY2Djgw1q1bV3G06fz58wesad3e3q5cLqedO3f22d7S0qLW1tY+2zo7\nO5XL5dTR0dFn+7Jly9Tc3NxnW6FQUC6X06ZNm/psz+fzampqGlDb3LlzQ3kf1113XSreR5Tfj3w+\nn4r3IY3e92PPnj2SpFL39o2S+lYgtUu6R9Lrvbb1PP/mm2+uifdRa9+PfD6fivchRfv9yOfzqXgf\n0uh/P/L5/Lt/GydMmKBcLqeFCxcOeE21IluO2My6JM1yzj04xHNYjhiIkXNOf3r00Zr429/q/ACv\ne0zSkwcfrNd37tQhhxwSUnUAhlKzyxGb2SFm9hEzm9K96QPdHx8T5n4B+DEzXXHVVdpSV6e3q3xN\nSdJPGxr015ddRiMAJFTYlwn+XNJPJT2j8joD31L5LOPXQ94vAE+XX365usz0eJXPf0rS7mJRV111\nVZhlAQhR2OsMPO6cq3PO1fd7zAtzvwD8TZw4UUtuukk/Vvn0/1AXEp+RtE7SNddcoylTpgzxTAC1\nrCYHECK4SoNNMDQyG9yXvvQlXX/99XpM0q0NDXpa0l6VG4P7JT0r6fv19fqRpCuvuko33XRTfMUm\nAMeaH3KLDs1ASrBSV3BkNjgz0z/90z9p48aNOn3mTD1kplZJ35C0RdJaSSeddZYeeOABrVixQnV1\n/CoZCseaH3KLTmSzCarBbAKgNnV2duqJJ57Qnj17dOihh+q0007TSSedFHdZAHoZyWwCbmEMYFiT\nJk3SpEmT4i4DQEg4twcAQMbRDKRE/xWsMDwy80NuwZGZH3KLDs1ACuzeLS1ZsiTuMhKHzPyQW3Bk\n5ofcokMzkHDbt0tHHSW99da9uu02qd/S2RjCvffeG3cJiURuwZGZH3KLDs1Awr33vdKyZZJzY3TF\nFdKECdL06dJtt0ncQG5oY8aMibuERCK34MjMD7lFh2Yg4Q4/XLrySmnDBuk3vyk3BsWidMUV0vjx\n0owZNAYAgKHRDKTI+PHSVVf1bQz27aMxAAAMjWYgJfrfJ3u4xqDnUkKWxxj0zwzVIbfgyMwPuUWH\nZiAlhloQplJj0HMpoWeMwfe+l73GgEV0/JBbcGTmh9yiw3LEGbZjh7R2rbRmjfTYY5KZdPbZ0pw5\n0gUXSEceGXeFAIBqjWQ5Ys4MZNj48eXBh+vXl88YLF/O4EMAyCKaAUja3xgw+BAAsodmICU6OjpG\n7Wv1H2OwfHk6Bx+OZmZZQm7BkZkfcosOzUBKLFq0KJSv2/+MQe9LCUkffBhWZmlHbsGRmR9yiw4D\nCFOis7Mz0pG3v/ud9MMfSvfdJz3+eN/Bh7NmlZdIrnVRZ5YW5BYcmfkht2AYQIjIf2DGjRv+jEGt\nX0rgl4wfcguOzPyQW3RoBjBiab6UAABZQDOAUVWpMdi3r7yNxgAAahPNQEq0trbGXcIAPY3Bxo19\nVz7s3RjEeSmhFjNLAnILjsz8kFt0aAZSolAoxF3CkKpZEjnqxqDWM6tV5BYcmfkht+gwmwCx2rGj\nPCthzZr9sxKmTpVmz2ZJZAAIgtkESCzurggA8aMZQM2oxUsJAJAFNAMpsTNlfyErLYk82tMV05ZZ\nVMgtODLzQ27RoRlIiXnz5sVdQmgGW8dgpNMV05xZmMgtODLzQ27RoRlIicWLF8ddQiQq3V2x0nTF\nau6umJXMRhu5BUdmfsgtOswmQCowKwFA1jGbAJnHrAQA8EczgNRhVgIABEMzkBIrV66Mu4SaVGlW\nQqlUbgzGjVvJvRI8cKwFR2Z+yC06NAMp0d4e6PJQJvUMPly/vtwYnHlmu/fgwyzjWAuOzPyQW3QY\nQIjMY/AhgDRgACEwAgw+BJB1NANAL9WsfEhjACBtaAaAQQy28uFoLokMALWAZiAlcrlc3CUkTpDM\nKq18uG/fyJdETiKOteDIzA+5RYdmICUWLFgQdwmJ45tZz6WEjRsrL4k8Y0a6ZyVwrAVHZn7ILTqh\nzyYws/mSrpU0QdKzkv7OOff0IM9lNgESa8cOae1a6b779s9KOPtsac4cadYs6aij4q4QQJrV7GwC\nM5sr6VuSWiR9VOVm4BEz49ciUqeaMQYMPgRQi8K+TLBQ0q3OuTudcx2SrpRUkMR9KZFqDD4EkCSh\nNQNmdoCkUyWt79nmytckHpXUGNZ+s6qtrS3uEhInqswGawySuvIhx1pwZOaH3KIT5pmBoyTVS9rR\nb/sOlccPYBTl8/m4S0icODKrNCuh54zB+PHJGHzIsRYcmfkht+jU5GyCmTNnKpfL9Xk0NjYO6BLX\nrVtXcerJ/PnzB9zgor29XblcTjv7nZdtaWlRa2trn22dnZ3K5XLq6Ojos33ZsmVqbm7us61QKCiX\ny2nTpk19tufzeTU1NQ2obe7cuaG8j5NPPjkV7yPK78fq1atjfR89sxIuuGCZrriiWcuX71/5cNy4\ngsaOzekrX9nU51JCLXw/brrpJo6rgO9j9erVqXgfUrTfj9WrV6fifUij//3I5/Pv/m2cMGGCcrmc\nFi5cOOA11QptNkH3ZYKCpM855x7stf12SYc75y6o8BpmEyDzmJUAwEdNziZwzu2T9IykqT3bzMy6\nP94c1n6BpGPwIYCohX2ZYKmky83sMjM7WdJ3JY2RdHvI+wVSoXdj8NpryR98CKA2hdoMOOfuU3nB\noW9I+qmkD0ua4Zx7Pcz9ZlGl60sYWtIyGzeuNgYfJi23WkBmfsgtOqEPIHTO3eKcO8459yfOuUbn\n3E/C3mcWTZ8+Pe4SEifJmcV52+Uk5xYXMvNDbtEJfTniIBhACIzMYIMPZ8+WLriAwYdAmtXkAEIA\n0atmgSMGHwLoj2YASKlKjUGpxOBDAAPRDKRE/0UrMLwsZdbTGKxfP/LBh1nKbbSQmR9yiw7NQEos\nWbIk7hISJ6uZDTf4cLjGIKu5jQSZ+SG36DCAMCUKhYLGjBkTdxmJQmZ97dgh/fCH0po1Q698SG7B\nkZkfcguGAYTgB8YDmfXV/4xBzxiD/isfFgrkFhTHmh9yiw7NAIABeo8x6Fn5kMGHQHrRDAAYUs/K\nh6Mx+BBAbaIZSIn+t8bE8MgsuPHjpZdeavYefJhVHGt+yC06NAMpMWnSpLhLSBwy89OTW6UxBlEt\niZw0HGt+yC06zCYAMKpYEhmIB7MJANSMSisf7tvH4EOgltEMAAhNT2OwcSODD4FaRjOQEh0dHXGX\nkDhk5sc3tyyPMeBY80Nu0aEZSIlFixbFXULikJmf0chtsLsr9l7gKE2NAceaH3KLDgMIU6Kzs5OR\ntwGRmZ8wc0vr4EOONT/kFgwDCMEPjAcy8xNmboOdMeg9+PB730veGQOONT/kFh2aAQA1qX9j0DP4\nkFkJwOijGQBQ8yrddrn3rIS0jTEAokYzkBKtra1xl5A4ZOYn7twqzUqo9cGHcWeWVOQWHZqBlCgU\nCnGXkDhk5qeWcqtmVkItjDGopcyShNyiw2wCAKmT1lkJwFCYTQAAvTD4EAiGZgBAqjH4EBgezUBK\n7OQ3WWBk5ifJuQ3VGIQ5+DDJmcWJ3KJDM5AS8+bNi7uExCEzP2nJLcrGIC2ZRY3cokMzkBKLFy+O\nu4TEITM/acyt0nTFUmlgY+A7xiCNmUWB3KLDbAIAGMSOHdIPfyitWbN/VsLUqftnJRx5ZNwVAvsx\nmwAAQlDpUkLv2y7PmMGsBKQDzQAAVGG4xoBZCUgymoGUWLlyZdwlJA6Z+SG34IMPycwPuUWHZiAl\n2tsDXR6CyMwXufVVzeDDu+9u51KCB4616DCAEABCUGlJZAYfIkwMIASAGlNpSWQGH6JW0QwAQMgq\nXUpg8CFqCc0AAEQoKbddRrbQDKRELpeLu4TEITM/5BbcYJkN1hj0vrtilhsDjrXo0AykxIIFC+Iu\nIRH27NmjVatW6etf/7oOO+ww3XrrrXr99dfjLitRONaCqyazahqDrI0x4FiLDrMJkAmdnZ264YYb\ndMcdd+mdd95WQ8N7JJmKxTdUX1+nuXPn6rrrvqrJkyfHXSrQB0sio1ojmU1AM4DUa29v1znnzNCe\nPX9UsfhRSadKOqz7s29J+pkaGp7RgQf+UQ8+2KapU6fGVywwhErTFc8+W5ozR5o1SzrqqLgrRJxq\ncmqhmX3VzJ4ws7fM7Pdh7QcYyssvv6xp06Zr9+6DVSxeIekz2t8ISNIhkj6hYvEK7d07Qeedl2Oh\nE9SsSpcS+i9wlOUxBvAX5piBAyTdJ+k7Ie4D3dra2uIuoSa1tCzWG28UVSpdrPIf/t629vr3QXJu\njvbtO0zXXrsowgqTh2MtuDAy62kM1q+XXnttf2OQpsGHHGvRCa0ZcM593Tn3bUlbwtoH9svn83GX\nUHN27dqlfD6vYvE0DWwEJOnn/T4+UKVSozZuXK9f/epXEVSYTBxrwYWd2bhx+xuDNA0+5FiLDrMJ\nUmL16tVxl1Bz7r33XpVKXZI+OsgzZlfYdooaGg7VqlWrQqws2TjWgosys0orH/asY5C0lQ851qJD\nM4DU2rZtm+rrj1DlswKDOUBdXeO0ffv2sMoCIsNtl1GtQM2Amd1oZl1DPEpmdtJIi5o5c6ZyuVyf\nR2Nj44DrR+vWrau4KMX8+fMH3Pqyvb1duVxOO/sd9S0tLWptbe2zrbOzU7lcTh0dHX22L1u2TM3N\nzX22FQoF5XI5bdq0qc/2fD6vpqamAbXNnTuX9xHR+ygWi5Ks+zNbJFW6/rhGfccOSF1de/X444/X\nzPvoLcnfD95HvO9j/Hjp858v6NBDc1q7dlOflQ/Hjcvr/e9vGjDGoBbfh5SO78dI30c+n3/3b+OE\nCROUy+W0cOHCAa+pVqCphWZ2pKThZrW+5Jwr9nrN5yXd7Jw7ooqvz9RCjJobb7xRX/vaN1QqfVnl\n8azV6FJDwwp98YtztWLFijDLA2rCYNMVe9YxYLpickQ2tdA5t8s59/wwj+LwXwmjrVIXmXVz5sxR\nqfS2pF8M8oxKZwq2qVjcpYsuuijEypKNYy24Ws5ssDEGtTD4sJZzS5sw1xk4xsw+IulYSfVm9pHu\nR5ALuKjS9OnT4y6h5pxwwgk655wZqq9/SlKp0jP6fexk9l86+eRT9MlPfjKCCpOJYy24pGRWaYxB\nnIMPk5JbGoS2AqGZrZJ0WYVPfcY59x+DvIbLBBhVmzdv1qc+dZZKpf8uKSepfpBnOkmPSnpC999/\nvy688MLIagRqXaUlkVn5sPbU5AqEzrkm51x9hUfFRgAIwxlnnKE777xDdXU/l9ldkl6Q1NXrGU7S\ndkn3SnpCS5cupREA+hnqjEHvSwnMSkguphYi9S655BI98sjDOuWU90j6gRoaVqj8x3+1Ghq+K2mV\njj++qPvuu29Eo3GBLOjfGLAkcjrQDKRE/6kp6GvatGnasuVZbd68WfPmfU4zZhyrP//zQ3Tppedq\n3bp1evHF5zV7dqVFiNAfx1pwac2s95LIYQw+TGtutYhmICWWLFkSdwk1z8zU2NioW2+9VQ8//LAm\nTpyo22+/Xeecc47q6vhRqBbHWnBZyCyMwYdZyK1WcAvjlCgUChozZkzcZSQKmfkht+CynNlIBh9m\nOTcfNTmAENHiByY4MvNDbsFlObORDD7Mcm5RoxkAAESi0uDDSo1BEm6ilDY0AwCAyFVa+bD3TZRm\nzJCefTbuKrODZiAl+t8AA8MjMz/kFhyZDa3njMHGjX0bg+XLyS0qNAMpMWnSpLhLSBwy80NuwZFZ\n9XpfSvjwh8ktKswmAAAgBZhNAAAAvNEMAACQcTQDKdHR0RF3CYlDZn7ILTgy80Nu0aEZSIlFixbF\nXULikJkfcguOzPyQW3RoBlJi+fLlcZeQOGTmh9yCIzM/5BYdmoGUYOpScGTmh9yCIzM/5BYdmgEA\nADKOZgAAgIyjGUiJ1tbWuEtIHDLzQ27BkZkfcosOzUBKFAqFuEtIHDLzQ27BkZkfcosOyxEDAJAC\nLEcMAAC80QwAAJBxNAMpsXPnzrhLSBwy80NuwZGZH3KLDs1ASsybNy/uEhKHzPyQW3Bk5ofcokMz\nkBKLFy+Ou4TEITM/5BYcmfkht+jQDKQEsy+CIzM/5BYcmfkht+jQDAAAkHE0AwAAZBzNQEqsXLky\n7hISh8z8kFtwZOaH3KJDM5AS7e2BFpuCyMwXuQVHZn7ILTosRwwAQAqwHDEAAPBGMwAAQMbRDAAA\nkHE0AymRy+XiLiFxyMwPuQVHZn7ILTo0AymxYMGCuEtIHDLzQ27BkZkfcosOswkAAEgBZhMAQA35\n4x//qNWrV+vcc/9CJ500WSee+EF9+tOf0fe//30VCoW4ywMGoBkAgFF011136eij/1QXXXSRHn20\nQy+8cLh+/ev36T//81X9zd/8rSZMOFo333yzaumsLBBKM2Bmx5rZbWb2kpkVzOwFM1tsZgeEsT9I\nbW1tcZeQOGTmh9wGt3TpUl122WXatWu8pKtVKn1B0l9IOk5dXZdK+nu98cZJuuaaa3TttdfSEAyD\nYy06YZ0ZOFmSSbpc0imSFkq6UtI3Q9pf5uXz+bhLSBwy80NulT300EP68pe/LOkTkj4naVyvz/68\n+7/vk/SXkv5CS5cuZe39YXCsRSeyAYRmdq2kK51zJw7xHAYQAkikM874hJ588jfq6vq8yv8vNJz/\nrUmT3tS2bb9WXR1XbDFySRlA+F5Jv49wfwAQieeee04//vFmdXWdpuoaAUk6XZ2dL+uRRx4JszSg\nKpE0A2aVFi2WAAAKbklEQVR2oqQFkr4bxf4AIEptbW2qrx+j8hXSav2pGhrGcV0cNSFQM2BmN5pZ\n1xCPkpmd1O8175f0kKTVzrnvj2bxAFALdu3apbq6wyTVB3iVqVQ6TLt27QqrLKBqQc8M/C+VW9/B\nHpMlvdTzZDM7WtIGSZucc1dUu5OZM2cql8v1eTQ2Ng7ooNetW1dxucr58+cPGJjT3t6uXC6nnTt3\n9tne0tKi1tbWPts6OzuVy+XU0dHRZ/uyZcvU3NzcZ1uhUFAul9OmTZv6bM/n82pqahpQ29y5c0N5\nH1OmTEnF+4jy+9HU1JSK9yFF+/2YPXt2Kt7HaH4/DjzwQEmlXp9ZI2lrr4/bJL0o6Z4+r6+rK+m5\n556rmffRX9zfj6amplS8D2n0vx/5fP7dv40TJkxQLpfTwoULB7ymWqENIOw+I7BB0tOS/tpVsSMG\nEPrL5/O6+OKL4y4jUcjMD7kNtHLlSl1++Rfl3D9IOrzCM7ZI+rN+295Rff3N+trX/qdaWlrCLzKB\nONaCGckAwlCage4zAo9L2ibpC+rVMjvndgzxOpoBAInz5ptvavz4iSoUPibp7Cpf9bTMHtL27S/r\nmGOOCbM8ZEQtziY4R9IHJE2V9Iqk30h6rfu/AJAqhx56qJqaPq/6+mck/aGKVxRUX/9jnX/++TQC\nqAmhNAPOuTucc/X9HnXOuSCjawAgMVpaWvT+949VQ8MPNPQs6jdVX/8DHXaYtHTpt6IqDxgSK12k\nRP8BKBgemfkht8rGjh2rjRvX65hjDldd3XclPSDpVZWvkr4s6XeSHlJ9/Qq97337tGHDep1wwgkx\nVlz7ONaiQzOQEkuWLIm7hMQhMz/kNrgPfOADeuaZp3X99S2aOPF3kr4n6XpJt0u6Re9734v6ylcW\n6rnnfqYpU6bEWmsScKxFJ7LliKvBAEJ/hUJBY8aMibuMRCEzP+RWnWKxqMcee0yvvPKK9u7dq2OP\nPVbTpk3TQQcdFHdpicGxFsxIBhA2hFMSosYPTHBk5ofcqtPQ0KBp06bFXUaicaxFh8sEAABkHM0A\nAAAZRzOQEv2XucTwyMwPuQVHZn7ILTo0AykxadKkuEtIHDLzQ27BkZkfcosOswkAAEiBWlyOGAAA\nJATNAAAAGUczkBL9752N4ZGZH3ILjsz8kFt0aAZSYtGiRXGXkDhk5ofcgiMzP+QWHZqBlFi+fHnc\nJSQOmfkht+DIzA+5RYdmICWYghMcmfkht+DIzA+5RYdmAACAjKMZAAAg42gGUqK1tTXuEhKHzPyQ\nW3Bk5ofcokMzkBKFQiHuEhKHzPyQW3Bk5ofcosNyxAAApADLEQMAAG80AwAAZBzNQErs3Lkz7hIS\nh8z8kFtwZOaH3KJDM5AS8+bNi7uExCEzP+QWHJn5Ibfo0AykxOLFi+MuIXHIzA+5BUdmfsgtOjQD\nKcHsi+DIzA+5BUdmfsgtOjQDAABkHM0AAAAZRzOQEitXroy7hMQhMz/kFhyZ+SG36NAMpER7e6DF\npiAy80VuwZGZH3KLDssRAwCQAixHDAAAvNEMAACQcTQDAABkHM1ASuRyubhLSBwy80NuwZGZH3KL\nDs1ASixYsCDuEhKHzPyQW3Bk5ofcosNsAgAAUoDZBAAAwBvNAAAAGUczkBJtbW1xl5A4ZOaH3IIj\nMz/kFh2agZRobW2Nu4TEITM/5BYcmfkht+iE1gyY2QNmtt3M9prZb8zsTjObGNb+sm7s2LFxl5A4\nZOaH3IIjMz/kFp0wzwxskDRb0kmSLpR0gqQ1Ie4PAAB4aAjrCzvnvt3rw1fM7F8krTWzeudcKaz9\nAgCAYCIZM2BmR0i6VNITNAIAANSW0M4MSFL32YAFksZI+rGk84Z5ycGStHXr1jDLSqWnnnqKe38H\nRGZ+yC04MvNDbsH0+tt5cNDXBlqB0MxulPSVIZ7iJE12zj3f/fwjJB0h6VhJLZL2OOcGbQjM7BJJ\nP6i6IAAA0N+lzrl7grwgaDNwpKQjh3naS865YoXXvl/SK5IanXNPDvH1Z0h6WdLbVRcGAAAOlnSc\npEecc7uCvDCyexOY2SSV/8h/2jn3H5HsFAAADCuUZsDMPi7pNEmbJP1B0omSviFprKQPOef2jfpO\nAQCAl7BmExRUXlvgUUkdkr4n6WcqnxWgEQAAoIbU1C2MAQBA9Lg3AQAAGUczAABAxtVsM8CNjoIz\ns2PN7DYze8nMCmb2gpktNrMD4q6tlpnZV83sCTN7y8x+H3c9tcrM5pvZtu6fyf8ys9PirqmWmdmZ\nZvagmb1qZl1mlou7plpnZv9oZk+Z2R4z22Fma83spLjrqnVmdqWZPWtmu7sfm83s3CBfo2abAXGj\nIx8nSzJJl0s6RdJCSVdK+macRSXAAZLuk/SduAupVWY2V9K3VF487KOSnpX0iJkdFWthte0QlQdO\nX63ygmwY3pmSlkk6XdI0lX8215nZn8RaVe17ReUFAT8m6VSV/34+YGaTq/0CiRlAaGbnS1or6SDu\nb1A9M7tW0pXOuRPjrqXWmdnnJd3snDsi7lpqjZn9l6QnnXP/0P2xqfwL6N+cc0tiLS4BzKxL0izn\n3INx15Ik3c3m7yR9yjm3Ke56ksTMdkm61jm3qprn1/KZgXdxo6MRea8kTn3DW/dlplMlre/Z5sr/\nF/GopMa46kImvFflsyr8DquSmdWZ2UXaf0+gqtR0M2Bm/2Jmb0raKekYSbNiLilRzOxElW8U9d24\na0GiHSWpXtKOftt3SJoQfTnIgu6zT/8qaZNz7pdx11PrzOxDZvaGpHck3SLpAudcR7Wvj7QZMLMb\nuwfSDPYo9RssskTSFEnnSCpJuivKemuFR24994J4SNJq59z346k8Pj6ZAagpt6g89umiuAtJiA5J\nH5H0cZXHP91pZidX++JIxwyEfaOjtAqam5kdLWmjpM3Ouaaw66tFPscaYwYq675MUJD0ud7XvM3s\ndkmHO+cuiKu2pGDMQDBmtlzS+ZLOdM51xl1PEpnZ/5P0onPuqmqe3xByPX1030Up0J2Ueqnv/u9B\no1ROYgTJrbtp2iDpaUnzwqyrlo3wWEMvzrl9ZvaMpKmSHpTePYU7VdK/xVkb0qe7EfispLNoBEak\nTgH+XkbaDFRriBsdvaAAAyKypvuMwGOStklaJGlc+Xe25Jzrf70X3czsGElHSDpWUr2ZfaT7Uy86\n596Kr7KaslTS7d1NwVMqT1sdI+n2OIuqZWZ2iMq/u6x70we6j63fO+deia+y2mVmt0i6WFJO0ltm\nNr77U7udc9zWfhBmdoPKl4U7Jb1H5QH3Z0maXvXXqMWphWb2IUnflvRhlefqvqbyG/2mc+61OGur\nZd2nufuPDzCVB3/XV3gJJJnZKkmXVfjUZ7jd9n5mdrXKTeZ4lefP/51z7ifxVlW7zOwslS/X9f8l\ne4dzLrNn7YbSfTml0h+lJufcnVHXkxRmdpuksyVNlLRb0nOS/sU5t6Hqr1GLzQAAAIhOTU8tBAAA\n4aMZAAAg42gGAADIOJoBAAAyjmYAAICMoxkAACDjaAYAAMg4mgEAADKOZgAAgIyjGQAAIONoBgAA\nyLj/D08Wk1EW+2GNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111bed358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=X[:,0], y=X[:,1], c=y, s=100)\n",
    "plt.plot(xl, yl)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual Lagrangian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "\n",
    "def dual_lagrangian_max_margin(X, y):\n",
    "    \"\"\" Solves for lagrangian weights in dual formulation for max-margin classification \n",
    "    \n",
    "    Note that this formulation is found by:\n",
    "    1. Expressing the primal formulation in terms of the weights for the hyperplane and \n",
    "        the lagrange multipliers times the constraints that make that hyperplane separating.\n",
    "            - The constraints are all >= 0 inequalities like 1 - y(w*x + b) >= 0\n",
    "            - The number of constraints is equal to number of data points (n), thus the number \n",
    "                of lagrange multipliers is also n\n",
    "    2. Differentiating primal by w and b, setting to 0, and then plugging those answers back\n",
    "        into the original observation problem.  These will come out as:\n",
    "            - w = sum(ai * yi * xi) over all i [where ai is lagrange multiplier i]\n",
    "            - b = not defined in solution for maximum value, though this differentiation does\n",
    "                give the important \"balance\" constraint (that sum(ai * yi) over all i = 0)\n",
    "    3. Those values placed back in the primal expression give the dual formulation with the\n",
    "        following constraints:\n",
    "            - sum(ai * yi) over all i = 0\n",
    "            - ai >= 0 for all i\n",
    "    4. And the dual lagrangian objective function is: \n",
    "            - L(a) = sum(ai) - 1/2 * sum(pairwise points[xi, xj] {ai aj yi yj <xi, xj>})\n",
    "            \n",
    "    This function will maximize the above function with respect to the lagrange multipliers ai\n",
    "    and return the optimization result (which will contain those weights)\n",
    "    \n",
    "    :param X: data matrix (n,p)\n",
    "    :param y: response array (n,) in {-1, 1}\n",
    "    :return scipy optimize result\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    def loss(w):\n",
    "        assert len(w) == n\n",
    "        \n",
    "        # Compute right half of L\n",
    "        l = 0\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                l += y[i]*y[j]*w[i]*w[j]*np.dot(X[i], X[j])\n",
    "                \n",
    "        # Add to left half of L\n",
    "        #L = np.sum(w) - .5 * l\n",
    "        \n",
    "        w1, w2, w3, w4 = w\n",
    "        L = np.sum(w) - (w1**2 + w1*w2 + w1*w3 + 3*w1*w4 + .5*w2*w2 + 2*w2*w3 + 2*w2*w4 + 2.5*w3*w3 + 3*w3*w4 + 2.5*w4*w4)\n",
    "        #l = 2*w2 + 2*w4 - w1**2 - w1*w2 - w1 * w3 + 3*w1*w4 - .5*w2**2 - 2*w2*w3 - 2*w2*w4 - 2.5*w3**2 - 3*w3*w4 - 2.5*w4**2\n",
    "        \n",
    "        # Return negative L to maximize\n",
    "        return -L\n",
    "\n",
    "    cons = (\n",
    "        {\n",
    "            'type': 'eq',\n",
    "            'fun' : lambda w: (w[1] + w[3]) - (w[0] + w[2])\n",
    "        },\n",
    "        {\n",
    "            'type': 'ineq',\n",
    "            'fun': lambda w: np.sum(w)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    x0 = np.zeros(n)\n",
    "    return minimize(\n",
    "        loss, x0, tol=1e-32,\n",
    "        method='SLSQP', \n",
    "        constraints=cons,\n",
    "        bounds=[(0., np.inf) for i in range(n)], \n",
    "        options={'disp': True}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: -0.4\n",
      "            Iterations: 12\n",
      "            Function evaluations: 55\n",
      "            Gradient evaluations: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: -0.40000000000000019\n",
       "     jac: array([ 0.20000001, -0.2       ,  0.20000003,  1.00000002,  0.        ])\n",
       " message: 'Positive directional derivative for linesearch'\n",
       "    nfev: 55\n",
       "     nit: 12\n",
       "    njev: 8\n",
       "  status: 8\n",
       " success: False\n",
       "       x: array([ 0.4,  0.4,  0. ,  0. ])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dual_lagrangian_max_margin(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: -0.4\n",
      "            Iterations: 31\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: -0.40000000000000019\n",
       "     jac: array([ 0.2       , -0.2       ,  0.20000004,  1.00000001,  0.        ])\n",
       " message: 'Positive directional derivative for linesearch'\n",
       "    nfev: 327\n",
       "     nit: 31\n",
       "    njev: 27\n",
       "  status: 8\n",
       " success: False\n",
       "       x: array([  3.99999996e-01,   3.99999996e-01,   2.58688200e-14,\n",
       "         2.75944946e-21])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dual_lagrangian_max_margin(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.99999996e-01,   3.99999996e-01,   2.58688200e-14,\n",
       "         2.75944946e-21])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.99999996e-01,   3.99999996e-01],\n",
       "       [  0.00000000e+00,   3.99999996e-01],\n",
       "       [ -2.58688200e-14,   5.17376401e-14],\n",
       "       [  2.75944946e-21,   5.51889891e-21]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wstar = np.array([res.x[i]*y[i]*X[i] for i in range(4)])\n",
    "#wstar = wstar.sum(axis=0)\n",
    "wstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4       ,  0.79999999])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wstar.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  5.66666667, -2.66666667,  0.33333333])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A = np.array([\n",
    "#     [2, -1, -1, 3],\n",
    "#     [-1, -1, -2, -2],\n",
    "#     [-1, -2, -5, -3],\n",
    "#     [3, -2, -3, -5]\n",
    "# ]) \n",
    "# Ainv = np.linalg.inv(A)\n",
    "# alphas = np.matmul(Ainv, np.array([0, -2, 0, -2]))\n",
    "# alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [2, 1, 1, 3],\n",
    "    [1, 1, 2, 2],\n",
    "    [1, 2, 5, 3],\n",
    "    [3, 2, 3, 5]#,\n",
    "    #[1, -1, 1, -1]\n",
    "]) \n",
    "#b = np.array([1, 1, 1, 1, 0])\n",
    "b = np.array([0, 2, 0, 0])\n",
    "#Ainv = np.linalg.inv(A)\n",
    "#alphas = np.matmul(Ainv, b)\n",
    "#alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.18787158,  0.04042806, -0.0665874 ,  0.22829964]),\n",
       " array([], dtype=float64),\n",
       " 2,\n",
       " array([  1.01400549e+01,   2.85994506e+00,   6.88218710e-16,\n",
       "          5.99439662e-18]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ inf,  0.5,  inf,  1.5],\n",
       "       [ inf,  0.5,  inf,  1. ],\n",
       "       [ inf,  1. ,  inf,  1.5],\n",
       "       [ inf,  1. ,  inf,  2.5]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ],\n",
       "       [ 0.        ,  5.66666667],\n",
       "       [ 2.66666667, -5.33333333],\n",
       "       [ 0.33333333,  0.66666667]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wstar = np.array([alphas[i]*y[i]*X[i] for i in range(4)])\n",
    "#wstar = wstar.sum(axis=0)\n",
    "wstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  2.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wstar.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.16666666666666674"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0] + z[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5000000000000004"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[1] + z[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 1],\n",
    "    [1, 0],\n",
    "    [1, -1],\n",
    "    [-1, -1],\n",
    "    [-1, 0],\n",
    "    [-1, 1]\n",
    "])\n",
    "y = np.array([1, 1, 1, -1, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (change = N)| index:0\tw: [-1.  2.] => [-1.  2.]\tb: 0.0 => 0.0\tH: y = 0.5 x + -0.0\n",
      "Step 1 (change = Y)| index:1\tw: [-1.  2.] => [ 0.  2.]\tb: 0.0 => 1.0\tH: y = -0.0 x + -0.5\n",
      "Step 2 (change = Y)| index:2\tw: [ 0.  2.] => [ 1.  1.]\tb: 1.0 => 2.0\tH: y = -1.0 x + -2.0\n",
      "Step 3 (change = Y)| index:3\tw: [ 1.  1.] => [ 2.  2.]\tb: 2.0 => 1.0\tH: y = -1.0 x + -0.5\n",
      "Step 4 (change = N)| index:4\tw: [ 2.  2.] => [ 2.  2.]\tb: 1.0 => 1.0\tH: y = -1.0 x + -0.5\n",
      "Step 5 (change = Y)| index:5\tw: [ 2.  2.] => [ 3.  1.]\tb: 1.0 => 0.0\tH: y = -3.0 x + -0.0\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Implementation of Perceptron Algorithm with assumption that correctly classified\n",
    "# points involve no weight update\n",
    "\n",
    "def sign(x, w, b):\n",
    "    s = int(np.sign(np.dot(x, w) + b) >= 0)\n",
    "    return -1 if s == 0 else 1\n",
    "\n",
    "\n",
    "def all_correct(X, y, w, b):\n",
    "    for i in range(len(y)):\n",
    "        xi = X[i]\n",
    "        yi = y[i]\n",
    "        if sign(xi, w, b) != yi:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def train(X, y):\n",
    "    \n",
    "    w = np.array([-1., 2.])\n",
    "    b = 0.\n",
    "    a = 1.\n",
    "    ct = -1\n",
    "    n = len(y)\n",
    "    \n",
    "    while True:\n",
    "        ct += 1\n",
    "        i = ct % n\n",
    "        \n",
    "        xi = X[i]\n",
    "        yi = y[i]\n",
    "        \n",
    "        s = sign(xi, w, b)\n",
    "        old = (w, b)\n",
    "        if s != yi:\n",
    "            w = w + a*(yi * xi)\n",
    "            b = b + a*(yi)    \n",
    "        h = 'y = {} x + {}'.format(-w[0]/w[1], -b/w[1])\n",
    "        change = 'Y' if s != yi else 'N'\n",
    "        print(\n",
    "            'Step {} (change = {})| index:{}\\tw: {} => {}\\tb: {} => {}\\tH: {}'\n",
    "            .format(ct, change, i, old[0], w, old[1], b, h)\n",
    "        )\n",
    "        \n",
    "        if i > 100:\n",
    "            raise AssertionError('Failed to converge after 100 steps')\n",
    "            \n",
    "        if all_correct(X, y, w, b):\n",
    "            break\n",
    "    print('Complete')\n",
    "train(X, y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
