{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -m ipy_startup\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Regression Data\n",
    "# n_vars = 2\n",
    "# n_samples = 1000\n",
    "# drop_pct = .5\n",
    "# w = np.random.randn(n_vars)\n",
    "# X = np.random.randn(n_samples, n_vars)\n",
    "# y = np.hstack((np.multiply(X, w), np.random.randn(n_samples, 1)))\n",
    "\n",
    "# y = np.sum(y, axis=1)\n",
    "# idx = np.random.choice(np.arange(len(y)), replace=True, size=int(len(y) * drop_pct))\n",
    "# y[idx] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classification Data\n",
    "n_vars = 2\n",
    "n_samples = 1000\n",
    "drop_pct = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, W, b, y, n_samples):\n",
    "    y_pred = tf.reshape(tf.add(tf.matmul(X, W), b), [-1])\n",
    "    y_fill = tf.select(tf.is_nan(y), y_pred, y)\n",
    "    loss = tf.reduce_sum(tf.pow(y_fill - y_pred, 2)) / n_samples\n",
    "    return W, b, y_pred, y_fill, loss\n",
    "\n",
    "# def predict(X, W, b, y, n_samples):\n",
    "#     y_pred = tf.reshape(tf.add(tf.matmul(X, W), b), [-1])\n",
    "#     loss = tf.reduce_sum(tf.pow(y - y_pred, 2)) / n_samples\n",
    "#     y_fill = None\n",
    "#     return W, b, y_pred, y_fill, loss\n",
    "\n",
    "def get_model(n_samples, n_vars):\n",
    "    Xi = tf.placeholder(tf.float32, shape=[n_samples, n_vars])\n",
    "    yi = tf.placeholder(tf.float32, shape=[n_samples])\n",
    "    \n",
    "    W = tf.Variable(tf.zeros([2,1]), name=\"weights\")\n",
    "    b = tf.Variable(tf.zeros([1]), name=\"bias\")\n",
    "    #b = tf.Variable(np.random.randn(), name='bias')\n",
    "    \n",
    "    W, b, y_pred, y_fill, loss = predict(Xi, W, b, yi, n_samples)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=.01).minimize(loss)\n",
    "    return W, b, Xi, yi, y_pred, y_fill, optimizer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "W, b, Xi, yi, y_pred, y_fill, optimizer, loss = get_model(n_samples, n_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Cost = 1.1217153072357178\n",
      "Iteration 11: Cost = 1.014649510383606\n",
      "Iteration 21: Cost = 0.9278941750526428\n",
      "Iteration 31: Cost = 0.8575946092605591\n",
      "Iteration 41: Cost = 0.8006275296211243\n",
      "Iteration 51: Cost = 0.7544631958007812\n",
      "Iteration 61: Cost = 0.7170517444610596\n",
      "Iteration 71: Cost = 0.6867326498031616\n",
      "Iteration 81: Cost = 0.6621610522270203\n",
      "Iteration 91: Cost = 0.6422466039657593\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init = tf.initialize_all_variables()\n",
    "yp = None\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        #print(sess.run(y_fill, feed_dict={Xi:X, yi:y}))\n",
    "        sess.run(optimizer, feed_dict={Xi:X, yi:y})\n",
    "        if i % 10 == 0:\n",
    "            c = sess.run(loss, feed_dict={Xi:X, yi:y})\n",
    "            print('Iteration {}: Cost = {}'.format(i + 1, c))\n",
    "    yp = sess.run(y_pred, feed_dict={Xi:X, yi:y})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.426084</td>\n",
       "      <td>0.521041</td>\n",
       "      <td>0.906908</td>\n",
       "      <td>-0.348892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.202492</td>\n",
       "      <td>1.816305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.411890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.300508</td>\n",
       "      <td>-0.231246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.635307</td>\n",
       "      <td>-0.065465</td>\n",
       "      <td>1.945041</td>\n",
       "      <td>0.450516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.406291</td>\n",
       "      <td>-0.029994</td>\n",
       "      <td>1.305311</td>\n",
       "      <td>0.292883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0        X1         y    y_pred\n",
       "0  0.426084  0.521041  0.906908 -0.348892\n",
       "1  0.202492  1.816305       NaN -0.411890\n",
       "2 -2.300508 -0.231246       NaN  1.581662\n",
       "3 -0.635307 -0.065465  1.945041  0.450516\n",
       "4 -0.406291 -0.029994  1.305311  0.292883"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(np.hstack([X, np.reshape(y, (-1, 1))])).add_prefix('X')\n",
    "d = d.rename(columns={d.columns[-1]:'y'})\n",
    "d['y_pred'] = yp\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116ad9b38>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEQCAYAAAC9VHPBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYUfAMAzT5bAjYBiG6XL+f52dNGZFYSGhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116c1d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.plot(kind='scatter', x='y_pred', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116c19ba8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEQCAYAAACqduMIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117725d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.plot(kind='scatter', x='y_pred', y='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TF Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000,))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_informative=2, n_classes=3, n_redundant=0, \n",
    "    n_features=10, n_clusters_per_class=1, class_sep=10, \n",
    "    random_state=123\n",
    ")\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X)).add_prefix('X')\n",
    "y = pd.Series(y)\n",
    "#clf = RandomForestClassifier().fit(X, y)\n",
    "clf = GradientBoostingClassifier().fit(X, y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11f859898>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f7c5d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(clf.feature_importances_, index=X.columns).sort_values().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>333.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual         0      1      2\n",
       "predicted                     \n",
       "0          332.0    NaN    NaN\n",
       "1            NaN  333.0    NaN\n",
       "2            NaN    NaN  335.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'predicted':clf.predict(X), 'actual': y.values}).groupby(['predicted', 'actual']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tfeval(exp):\n",
    "    sess = tf.InteractiveSession()\n",
    "    res = sess.run(exp)\n",
    "    sess.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.23606801,  5.        ], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1.,2], [3,4]])\n",
    "v = x * x\n",
    "v = tf.sqrt(tf.reduce_sum(v, 1, keep_dims=False))\n",
    "tfeval(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn.python.learn as learn\n",
    "from sklearn import metrics\n",
    "\n",
    "def my_model(X, y, mode, params):\n",
    "    print(params)\n",
    "    a1=params['a1']\n",
    "    a2=params['a2']\n",
    "    a3=params['a3']\n",
    "    yt = tf.one_hot(y, 3)\n",
    "    \n",
    "    b1 = tf.Variable(tf.zeros([3]), name='b1')\n",
    "\n",
    "    W1 = tf.Variable(tf.random_normal([5, 3]), name='W1')\n",
    "    W2 = tf.Variable(tf.random_normal([5, 3]), name='W2')\n",
    "    \n",
    "    h1 = tf.matmul(X[:,0:5], W1)\n",
    "    h2 = tf.matmul(X[:,5:10], W2)\n",
    "    \n",
    "    w1 = tf.Variable(tf.zeros([3]))\n",
    "    w2 = tf.Variable(tf.zeros([3]))\n",
    "    h3 = tf.add(tf.mul(h1, w1), tf.mul(h2, w2)) + b1\n",
    "    yp = tf.nn.softmax(h3)\n",
    "    \n",
    "    loss_y = tf.reduce_mean(-tf.reduce_sum(yt * tf.log(yp), reduction_indices=[1]), name='loss_y')\n",
    "    \n",
    "    \n",
    "    loss_W1_min = -tf.minimum(tf.reduce_min(W1), 0, name='loss_W1_min')\n",
    "    loss_W1_reg = tf.reduce_sum(tf.sqrt(tf.reduce_sum(tf.pow(W1, 2), 1, keep_dims=True)), name='loss_W1_reg')\n",
    "    loss_W1 = tf.mul(a1, tf.add(loss_W1_min, loss_W1_reg), name='loss_W1')\n",
    "\n",
    "    loss_W2_min = -tf.minimum(tf.reduce_min(W2), 0, name='loss_W2_min')\n",
    "    loss_W2_reg = tf.reduce_sum(tf.sqrt(tf.reduce_sum(tf.pow(W2, 2), 1, keep_dims=True)), name='loss_W2_reg')\n",
    "    loss_W2 = tf.mul(a2, tf.add(loss_W2_min, loss_W2_reg), name='loss_W2')\n",
    "    \n",
    "    loss_w = tf.mul(a3, tf.reduce_sum(tf.abs(tf.concat(0, [w1, w2]))), name='loss_w')\n",
    "\n",
    "    loss = tf.identity(loss_y + loss_W1 + loss_W2 + loss_w, name='loss')\n",
    "    \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss, tf.contrib.framework.get_global_step(), optimizer='Adagrad',\n",
    "        learning_rate=0.1)\n",
    "    return yp, loss, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpe0axladb\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Step 1: loss_y = 1.09861, loss_W2 = 0.0929058, loss_w = 0.0, loss_W1 = 0.106699\n",
      "INFO:tensorflow:Step 1: loss = 1.29822\n",
      "INFO:tensorflow:Saving checkpoints for 60 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpe0axladb/model.ckpt.\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-482c00d13283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmonitor_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m ]\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;31m#score = metrics.accuracy_score(y.values, classifier.predict(X.values))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#print(\"Accuracy: %f\" % score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    238\u001b[0m                              \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                              \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                              max_steps=max_steps)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps)\u001b[0m\n\u001b[1;32m    577\u001b[0m           \u001b[0mfail_on_nan_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfail_on_nan_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m           \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m           max_steps=max_steps)\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extract_metric_update_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\u001b[0m in \u001b[0;36m_supervised_train\u001b[0;34m(graph, output_dir, train_op, loss_op, global_step_tensor, init_op, init_feed_dict, init_fn, log_every_steps, supervisor_is_chief, supervisor_master, supervisor_save_model_secs, keep_checkpoint_max, supervisor_save_summaries_steps, feed_fn, steps, fail_on_nan_loss, monitors, max_steps)\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuper_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         _, loss = super_sess.run([train_op, loss_op], feed_fn() if feed_fn else\n\u001b[0;32m--> 281\u001b[0;31m                                  None)\n\u001b[0m\u001b[1;32m    282\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/supervised_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \"\"\"\n\u001b[1;32m    269\u001b[0m     return self._sess.run(fetches, feed_dict=feed_dict, options=options,\n\u001b[0;32m--> 270\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/recoverable_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         return self._sess.run(fetches, feed_dict=feed_dict, options=options,\n\u001b[0;32m---> 54\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m     55\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAbortedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/coordinated_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_monitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m       \u001b[0minduce_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitors_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minduce_stop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mstep_end\u001b[0;34m(self, step, output)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEveryN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_every_n_step_begin_called\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevery_n_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\u001b[0m in \u001b[0;36mevery_n_step_end\u001b[0;34m(self, step, outputs)\u001b[0m\n\u001b[1;32m    685\u001b[0m     outputs = self._estimator.evaluate(\n\u001b[1;32m    686\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         steps=self.eval_steps, metrics=self.metrics, name=self.name)\n\u001b[0m\u001b[1;32m    688\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, input_fn, feed_fn, batch_size, steps, metrics, name)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                                      \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                                                      \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                                                      name=name)\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0meval_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'global_step'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[0;34m(self, input_fn, steps, feed_fn, metrics, name)\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m       \u001b[0meval_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_eval_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m       \u001b[0mupdate_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_metric_update_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m       eval_results, current_global_step = graph_actions.evaluate(\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_get_eval_ops\u001b[0;34m(self, features, targets, metrics)\u001b[0m\n\u001b[1;32m    848\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m     \"\"\"\n\u001b[0;32m--> 850\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, targets, mode)\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'mode'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'params'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-232-482c00d13283>\u001b[0m in \u001b[0;36mmy_model\u001b[0;34m(X, y, mode, params)\u001b[0m\n\u001b[1;32m     39\u001b[0m     train_op = tf.contrib.layers.optimize_loss(\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adagrad'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         learning_rate=0.1)\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\u001b[0m in \u001b[0;36moptimize_loss\u001b[0;34m(loss, global_step, learning_rate, optimizer, gradient_noise_scale, gradient_multipliers, clip_gradients, moving_average_decay, learning_rate_decay_fn, update_ops, variables, name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# Compute gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# Optionally add gradient noise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                 \u001b[0min_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_AsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_AddGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    499\u001b[0m   \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_gradient_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m   return (array_ops.reshape(math_ops.reduce_sum(grad, rx), sx),\n\u001b[0;32m--> 501\u001b[0;31m           array_ops.reshape(math_ops.reduce_sum(grad, ry), sy))\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   1748\u001b[0m   \"\"\"\n\u001b[1;32m   1749\u001b[0m   result = _op_def_lib.apply_op(\"Reshape\", tensor=tensor, shape=shape,\n\u001b[0;32m-> 1750\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   1751\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eczech/anaconda/envs/research3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m           \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mbase_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "classifier = learn.Estimator(model_fn=my_model, params=dict(a1=.01, a2=.01, a3=.01))\n",
    "monitor_loss = learn.monitors.CaptureVariable('loss', every_n=1)\n",
    "monitors = [\n",
    "    learn.monitors.PrintTensor(['loss_y', 'loss_W1', 'loss_W2', 'loss_w']),\n",
    "    learn.monitors.ValidationMonitor(X.values, y.values, early_stopping_rounds=50),\n",
    "    monitor_loss\n",
    "]\n",
    "classifier.fit(X.values, y.values, max_steps=1000, monitors=monitors)\n",
    "#score = metrics.accuracy_score(y.values, classifier.predict(X.values))\n",
    "#print(\"Accuracy: %f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "??learn.Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class LearnClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, model_fn, model_params=None, model_config=None):\n",
    "        self.model_fn = model_fn\n",
    "        self.model_params = model_params\n",
    "        self.model_config = model_config\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        assert 'monitors' not in kwargs, \\\n",
    "            'Monitors should not be passed directly to the fit function, '\\\n",
    "            'instead a monitor_fn argument should be supplied that takes '\\\n",
    "            'as input the X and y values to fit on and returns a map of '\\\n",
    "            'monitors keyed by name for later reference'\n",
    "        self.monitors_ = None\n",
    "        if 'monitor_fn' in kwargs:\n",
    "            self.monitors_ = kwargs['monitor_fn'](X, y)\n",
    "            assert isinstance(self.monitors_, dict), 'Monitor map must be a dictionary'\n",
    "            del kwargs['monitor_fn']\n",
    "        self.classifier_ = learn.Estimator(model_fn=self.model_fn, params=self.model_params, config=self.model_config)\n",
    "        self.classifier_.fit(X, y, monitors=list(self.monitors_.values()), **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.classifier_.predict(X), axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.classifier_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Step 1: loss_y = 1.09861, loss_W2 = 0.0929058, loss_w = 0.0, loss_W1 = 0.106699\n",
      "INFO:tensorflow:Step 1: loss = 1.29822\n",
      "INFO:tensorflow:Skipping evaluation since model has not been saved yet at step 100.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Step 101: loss_y = 0.186799, loss_W2 = 0.0836254, loss_w = 0.0488194, loss_W1 = 0.0827462\n",
      "INFO:tensorflow:Step 101: loss = 0.40199\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-100-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 100.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 100 step: loss = 0.40199\n",
      "INFO:tensorflow:Validation (step 200): global_step = 100, loss = 0.40199\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Step 201: loss_y = 0.0521592, loss_W2 = 0.077847, loss_w = 0.0643389, loss_W1 = 0.0620415\n",
      "INFO:tensorflow:Step 201: loss = 0.256387\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-200-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 200.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 200 step: loss = 0.256387\n",
      "INFO:tensorflow:Validation (step 300): global_step = 200, loss = 0.256387\n",
      "INFO:tensorflow:Saving checkpoints for 300 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Step 301: loss_y = 0.0362472, loss_W2 = 0.0724959, loss_w = 0.0690335, loss_W1 = 0.0455563\n",
      "INFO:tensorflow:Step 301: loss = 0.223333\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-300-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 300.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 300 step: loss = 0.223333\n",
      "INFO:tensorflow:Validation (step 400): global_step = 300, loss = 0.223333\n",
      "INFO:tensorflow:Saving checkpoints for 400 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Step 401: loss_y = 0.0310968, loss_W2 = 0.0706063, loss_w = 0.0710914, loss_W1 = 0.0301329\n",
      "INFO:tensorflow:Step 401: loss = 0.202927\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-400-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 400.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 400 step: loss = 0.202927\n",
      "INFO:tensorflow:Validation (step 500): global_step = 400, loss = 0.202927\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Step 501: loss_y = 0.0287554, loss_W2 = 0.0688061, loss_w = 0.0720146, loss_W1 = 0.0159913\n",
      "INFO:tensorflow:Step 501: loss = 0.185567\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-500-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 500.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 500 step: loss = 0.185567\n",
      "INFO:tensorflow:Validation (step 600): global_step = 500, loss = 0.185567\n",
      "INFO:tensorflow:Saving checkpoints for 600 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Step 601: loss_y = 0.0275603, loss_W2 = 0.0674068, loss_w = 0.0724571, loss_W1 = 0.00544417\n",
      "INFO:tensorflow:Step 601: loss = 0.172868\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-600-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 600.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 600 step: loss = 0.172868\n",
      "INFO:tensorflow:Validation (step 700): global_step = 600, loss = 0.172868\n",
      "INFO:tensorflow:Saving checkpoints for 700 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Step 701: loss_y = 0.0268598, loss_W2 = 0.0677462, loss_w = 0.0726649, loss_W1 = 0.0018138\n",
      "INFO:tensorflow:Step 701: loss = 0.169085\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-700-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 700.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 700 step: loss = 0.169085\n",
      "INFO:tensorflow:Validation (step 800): global_step = 700, loss = 0.169085\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Step 801: loss_y = 0.0264448, loss_W2 = 0.0679971, loss_w = 0.0727322, loss_W1 = 9.58395e-05\n",
      "INFO:tensorflow:Step 801: loss = 0.16727\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-800-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 800.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 800 step: loss = 0.16727\n",
      "INFO:tensorflow:Validation (step 900): global_step = 800, loss = 0.16727\n",
      "INFO:tensorflow:Saving checkpoints for 900 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Step 901: loss_y = 0.0261946, loss_W2 = 0.0682122, loss_w = 0.0727085, loss_W1 = 9.90003e-05\n",
      "INFO:tensorflow:Step 901: loss = 0.167214\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-900-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 900.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 900 step: loss = 0.167214\n",
      "INFO:tensorflow:Validation (step 1000): global_step = 900, loss = 0.167214\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.167154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5jfoseon/model.ckpt-1000-?????-of-00001.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Step 1: loss_y = 1.09861, loss_W2 = 0.0929058, loss_w = 0.0, loss_W1 = 0.106699\n",
      "INFO:tensorflow:Step 1: loss = 1.29822\n",
      "INFO:tensorflow:Skipping evaluation since model has not been saved yet at step 100.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Step 101: loss_y = 0.154931, loss_W2 = 0.0863789, loss_w = 0.0602108, loss_W1 = 0.0829347\n",
      "INFO:tensorflow:Step 101: loss = 0.384455\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-100-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 100.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 100 step: loss = 0.384455\n",
      "INFO:tensorflow:Validation (step 200): global_step = 100, loss = 0.384455\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Step 201: loss_y = 0.0708982, loss_W2 = 0.0830026, loss_w = 0.0728317, loss_W1 = 0.0621805\n",
      "INFO:tensorflow:Step 201: loss = 0.288913\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-200-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 200.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 200 step: loss = 0.288913\n",
      "INFO:tensorflow:Validation (step 300): global_step = 200, loss = 0.288913\n",
      "INFO:tensorflow:Saving checkpoints for 300 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Step 301: loss_y = 0.0621483, loss_W2 = 0.0777881, loss_w = 0.0735227, loss_W1 = 0.0456666\n",
      "INFO:tensorflow:Step 301: loss = 0.259126\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-300-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 300.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 300 step: loss = 0.259126\n",
      "INFO:tensorflow:Validation (step 400): global_step = 300, loss = 0.259126\n",
      "INFO:tensorflow:Saving checkpoints for 400 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Step 401: loss_y = 0.0590147, loss_W2 = 0.0726249, loss_w = 0.0734177, loss_W1 = 0.0302387\n",
      "INFO:tensorflow:Step 401: loss = 0.235296\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-400-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 400.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 400 step: loss = 0.235296\n",
      "INFO:tensorflow:Validation (step 500): global_step = 400, loss = 0.235296\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Step 501: loss_y = 0.0581819, loss_W2 = 0.0681811, loss_w = 0.0730158, loss_W1 = 0.016074\n",
      "INFO:tensorflow:Step 501: loss = 0.215453\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-500-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 500.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 500 step: loss = 0.215453\n",
      "INFO:tensorflow:Validation (step 600): global_step = 500, loss = 0.215453\n",
      "INFO:tensorflow:Saving checkpoints for 600 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Step 601: loss_y = 0.0583899, loss_W2 = 0.0656757, loss_w = 0.072506, loss_W1 = 0.00549526\n",
      "INFO:tensorflow:Step 601: loss = 0.202067\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-600-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 600.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 600 step: loss = 0.202067\n",
      "INFO:tensorflow:Validation (step 700): global_step = 600, loss = 0.202067\n",
      "INFO:tensorflow:Saving checkpoints for 700 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Step 701: loss_y = 0.058386, loss_W2 = 0.0651769, loss_w = 0.072095, loss_W1 = 0.00183956\n",
      "INFO:tensorflow:Step 701: loss = 0.197498\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-700-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 700.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 700 step: loss = 0.197498\n",
      "INFO:tensorflow:Validation (step 800): global_step = 700, loss = 0.197498\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Step 801: loss_y = 0.0582551, loss_W2 = 0.065182, loss_w = 0.0718366, loss_W1 = 8.87818e-05\n",
      "INFO:tensorflow:Step 801: loss = 0.195363\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-800-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 800.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 800 step: loss = 0.195363\n",
      "INFO:tensorflow:Validation (step 900): global_step = 800, loss = 0.195363\n",
      "INFO:tensorflow:Saving checkpoints for 900 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Step 901: loss_y = 0.058126, loss_W2 = 0.0652911, loss_w = 0.0715537, loss_W1 = 9.08444e-05\n",
      "INFO:tensorflow:Step 901: loss = 0.195062\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-900-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 900.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 900 step: loss = 0.195062\n",
      "INFO:tensorflow:Validation (step 1000): global_step = 900, loss = 0.195062\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.194708.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpprvwit57/model.ckpt-1000-?????-of-00001.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Step 1: loss_y = 1.09861, loss_W2 = 0.0929058, loss_w = 0.0, loss_W1 = 0.106699\n",
      "INFO:tensorflow:Step 1: loss = 1.29822\n",
      "INFO:tensorflow:Skipping evaluation since model has not been saved yet at step 100.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Step 101: loss_y = 0.135454, loss_W2 = 0.0863113, loss_w = 0.0304917, loss_W1 = 0.0827579\n",
      "INFO:tensorflow:Step 101: loss = 0.335015\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-100-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 100.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 100 step: loss = 0.335015\n",
      "INFO:tensorflow:Validation (step 200): global_step = 100, loss = 0.335015\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Step 201: loss_y = 0.0344868, loss_W2 = 0.0833674, loss_w = 0.0408676, loss_W1 = 0.0620426\n",
      "INFO:tensorflow:Step 201: loss = 0.220764\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-200-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 200.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 200 step: loss = 0.220764\n",
      "INFO:tensorflow:Validation (step 300): global_step = 200, loss = 0.220764\n",
      "INFO:tensorflow:Saving checkpoints for 300 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Step 301: loss_y = 0.0247151, loss_W2 = 0.0767429, loss_w = 0.0439796, loss_W1 = 0.045553\n",
      "INFO:tensorflow:Step 301: loss = 0.190991\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-300-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 300.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 300 step: loss = 0.190991\n",
      "INFO:tensorflow:Validation (step 400): global_step = 300, loss = 0.190991\n",
      "INFO:tensorflow:Saving checkpoints for 400 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Step 401: loss_y = 0.0218599, loss_W2 = 0.0694193, loss_w = 0.0455305, loss_W1 = 0.0301319\n",
      "INFO:tensorflow:Step 401: loss = 0.166942\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-400-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 400.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 400 step: loss = 0.166942\n",
      "INFO:tensorflow:Validation (step 500): global_step = 400, loss = 0.166942\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Step 501: loss_y = 0.0206325, loss_W2 = 0.0632547, loss_w = 0.0464124, loss_W1 = 0.0159866\n",
      "INFO:tensorflow:Step 501: loss = 0.146286\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-500-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 500.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 500 step: loss = 0.146286\n",
      "INFO:tensorflow:Validation (step 600): global_step = 500, loss = 0.146286\n",
      "INFO:tensorflow:Saving checkpoints for 600 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Step 601: loss_y = 0.0200582, loss_W2 = 0.0619944, loss_w = 0.047023, loss_W1 = 0.00544297\n",
      "INFO:tensorflow:Step 601: loss = 0.134519\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-600-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 600.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 600 step: loss = 0.134519\n",
      "INFO:tensorflow:Validation (step 700): global_step = 600, loss = 0.134519\n",
      "INFO:tensorflow:Saving checkpoints for 700 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Step 701: loss_y = 0.019759, loss_W2 = 0.0613944, loss_w = 0.0474626, loss_W1 = 0.00179538\n",
      "INFO:tensorflow:Step 701: loss = 0.130411\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-700-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 700.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 700 step: loss = 0.130411\n",
      "INFO:tensorflow:Validation (step 800): global_step = 700, loss = 0.130411\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Step 801: loss_y = 0.0195896, loss_W2 = 0.0607975, loss_w = 0.0478414, loss_W1 = 0.000141489\n",
      "INFO:tensorflow:Step 801: loss = 0.12837\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-800-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 800.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 800 step: loss = 0.12837\n",
      "INFO:tensorflow:Validation (step 900): global_step = 800, loss = 0.12837\n",
      "INFO:tensorflow:Saving checkpoints for 900 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Step 901: loss_y = 0.0194904, loss_W2 = 0.0601786, loss_w = 0.0481649, loss_W1 = 0.000104947\n",
      "INFO:tensorflow:Step 901: loss = 0.127939\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-900-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 900.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 900 step: loss = 0.127939\n",
      "INFO:tensorflow:Validation (step 1000): global_step = 900, loss = 0.127939\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.127551.\n",
      "INFO:tensorflow:Loading model from checkpoint: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp4cbx6z6w/model.ckpt-1000-?????-of-00001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Step 1: loss_y = 1.09861, loss_W2 = 0.0929058, loss_w = 0.0, loss_W1 = 0.106699\n",
      "INFO:tensorflow:Step 1: loss = 1.29822\n",
      "INFO:tensorflow:Skipping evaluation since model has not been saved yet at step 100.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Step 101: loss_y = 0.132923, loss_W2 = 0.0866929, loss_w = 0.0321284, loss_W1 = 0.0829375\n",
      "INFO:tensorflow:Step 101: loss = 0.334682\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-100-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 100.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 100 step: loss = 0.334682\n",
      "INFO:tensorflow:Validation (step 200): global_step = 100, loss = 0.334682\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Step 201: loss_y = 0.0657341, loss_W2 = 0.0824958, loss_w = 0.0387216, loss_W1 = 0.062232\n",
      "INFO:tensorflow:Step 201: loss = 0.249184\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-200-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 200.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 200 step: loss = 0.249184\n",
      "INFO:tensorflow:Validation (step 300): global_step = 200, loss = 0.249184\n",
      "INFO:tensorflow:Saving checkpoints for 300 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Step 301: loss_y = 0.0573539, loss_W2 = 0.0762205, loss_w = 0.0404549, loss_W1 = 0.0457252\n",
      "INFO:tensorflow:Step 301: loss = 0.219755\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-300-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 300.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 300 step: loss = 0.219755\n",
      "INFO:tensorflow:Validation (step 400): global_step = 300, loss = 0.219755\n",
      "INFO:tensorflow:Saving checkpoints for 400 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Step 401: loss_y = 0.0542026, loss_W2 = 0.0699722, loss_w = 0.0415054, loss_W1 = 0.0302806\n",
      "INFO:tensorflow:Step 401: loss = 0.195961\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-400-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 400.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 400 step: loss = 0.195961\n",
      "INFO:tensorflow:Validation (step 500): global_step = 400, loss = 0.195961\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Step 501: loss_y = 0.0532689, loss_W2 = 0.0644621, loss_w = 0.042297, loss_W1 = 0.0161192\n",
      "INFO:tensorflow:Step 501: loss = 0.176147\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-500-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 500.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 500 step: loss = 0.176147\n",
      "INFO:tensorflow:Validation (step 600): global_step = 500, loss = 0.176147\n",
      "INFO:tensorflow:Saving checkpoints for 600 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Step 601: loss_y = 0.0535878, loss_W2 = 0.0605517, loss_w = 0.0428272, loss_W1 = 0.00547119\n",
      "INFO:tensorflow:Step 601: loss = 0.162438\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-600-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 600.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 600 step: loss = 0.162438\n",
      "INFO:tensorflow:Validation (step 700): global_step = 600, loss = 0.162438\n",
      "INFO:tensorflow:Saving checkpoints for 700 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Step 701: loss_y = 0.053987, loss_W2 = 0.0585157, loss_w = 0.0433327, loss_W1 = 0.00181845\n",
      "INFO:tensorflow:Step 701: loss = 0.157654\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-700-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 700.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 700 step: loss = 0.157654\n",
      "INFO:tensorflow:Validation (step 800): global_step = 700, loss = 0.157654\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Step 801: loss_y = 0.0540521, loss_W2 = 0.0574353, loss_w = 0.0437969, loss_W1 = 8.2428e-05\n",
      "INFO:tensorflow:Step 801: loss = 0.155367\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-800-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 800.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 800 step: loss = 0.155367\n",
      "INFO:tensorflow:Validation (step 900): global_step = 800, loss = 0.155367\n",
      "INFO:tensorflow:Saving checkpoints for 900 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Step 901: loss_y = 0.0539423, loss_W2 = 0.0567173, loss_w = 0.0442422, loss_W1 = 7.56562e-05\n",
      "INFO:tensorflow:Step 901: loss = 0.154977\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-900-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 900.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 900 step: loss = 0.154977\n",
      "INFO:tensorflow:Validation (step 1000): global_step = 900, loss = 0.154977\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.154697.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.01, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5_p0kk4t/model.ckpt-1000-?????-of-00001.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Step 1: loss_y = 1.09861, loss_W2 = 0.0929058, loss_w = 0.0, loss_W1 = 0.106699\n",
      "INFO:tensorflow:Step 1: loss = 1.29822\n",
      "INFO:tensorflow:Skipping evaluation since model has not been saved yet at step 100.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Step 101: loss_y = 0.198064, loss_W2 = 0.082784, loss_w = 0.0540523, loss_W1 = 0.0827825\n",
      "INFO:tensorflow:Step 101: loss = 0.417683\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt-100-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 100.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 100 step: loss = 0.417683\n",
      "INFO:tensorflow:Validation (step 200): global_step = 100, loss = 0.417683\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Step 201: loss_y = 0.0669573, loss_W2 = 0.0775829, loss_w = 0.0726939, loss_W1 = 0.0620808\n",
      "INFO:tensorflow:Step 201: loss = 0.279315\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt-200-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 200.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 200 step: loss = 0.279315\n",
      "INFO:tensorflow:Validation (step 300): global_step = 200, loss = 0.279315\n",
      "INFO:tensorflow:Saving checkpoints for 300 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Step 301: loss_y = 0.0557302, loss_W2 = 0.0734767, loss_w = 0.0758477, loss_W1 = 0.0455932\n",
      "INFO:tensorflow:Step 301: loss = 0.250648\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt-300-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 300.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 300 step: loss = 0.250648\n",
      "INFO:tensorflow:Validation (step 400): global_step = 300, loss = 0.250648\n",
      "INFO:tensorflow:Saving checkpoints for 400 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Step 401: loss_y = 0.0518729, loss_W2 = 0.0711881, loss_w = 0.0765848, loss_W1 = 0.0301702\n",
      "INFO:tensorflow:Step 401: loss = 0.229816\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt-400-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 400.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 400 step: loss = 0.229816\n",
      "INFO:tensorflow:Validation (step 500): global_step = 400, loss = 0.229816\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Step 501: loss_y = 0.0494366, loss_W2 = 0.0692725, loss_w = 0.0765141, loss_W1 = 0.0160268\n",
      "INFO:tensorflow:Step 501: loss = 0.21125\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt-500-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 500.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 500 step: loss = 0.21125\n",
      "INFO:tensorflow:Validation (step 600): global_step = 500, loss = 0.21125\n",
      "INFO:tensorflow:Saving checkpoints for 600 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Step 601: loss_y = 0.0478343, loss_W2 = 0.0674765, loss_w = 0.0762873, loss_W1 = 0.0054595\n",
      "INFO:tensorflow:Step 601: loss = 0.197058\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt-600-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 600.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 600 step: loss = 0.197058\n",
      "INFO:tensorflow:Validation (step 700): global_step = 600, loss = 0.197058\n",
      "INFO:tensorflow:Saving checkpoints for 700 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Step 701: loss_y = 0.0466776, loss_W2 = 0.0672378, loss_w = 0.0758569, loss_W1 = 0.00182166\n",
      "INFO:tensorflow:Step 701: loss = 0.191594\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt-700-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 700.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 700 step: loss = 0.191594\n",
      "INFO:tensorflow:Validation (step 800): global_step = 700, loss = 0.191594\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Step 801: loss_y = 0.0455845, loss_W2 = 0.0675013, loss_w = 0.0752851, loss_W1 = 7.58358e-05\n",
      "INFO:tensorflow:Step 801: loss = 0.188447\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt-800-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 800.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 800 step: loss = 0.188447\n",
      "INFO:tensorflow:Validation (step 900): global_step = 800, loss = 0.188447\n",
      "INFO:tensorflow:Saving checkpoints for 900 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Step 901: loss_y = 0.0447126, loss_W2 = 0.0677172, loss_w = 0.0746865, loss_W1 = 0.000105496\n",
      "INFO:tensorflow:Step 901: loss = 0.187222\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a2': 0.01, 'a3': 0.02, 'a1': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt-900-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 900.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 900 step: loss = 0.187222\n",
      "INFO:tensorflow:Validation (step 1000): global_step = 900, loss = 0.187222\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmpcwcsyyaq/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.186128.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "#clfx.set_params(params=dict(a1=.01, a2=.01, a3=.02))\n",
    "grid = {\n",
    "    'model_fn': [my_model],\n",
    "    'model_params': [dict(a1=.01, a2=.01, a3=.02), dict(a1=.01, a2=.01, a3=.01)]\n",
    "}\n",
    "\n",
    "def monitor_fn(X, y):\n",
    "    return {\n",
    "        'print': learn.monitors.PrintTensor(['loss_y', 'loss_W1', 'loss_W2', 'loss_w']),\n",
    "        'validate': learn.monitors.ValidationMonitor(X, y, early_stopping_rounds=10),\n",
    "        'loss': learn.monitors.CaptureVariable('loss', every_n=1)\n",
    "    }\n",
    "\n",
    "clf = LearnClassifier(\n",
    "    model_fn=my_model, \n",
    "    model_params=dict(a1=.01, a2=.01, a3=.01),\n",
    "    model_config=learn.run_config.RunConfig(save_checkpoints_secs=100)\n",
    ")\n",
    "clf_grid = GridSearchCV(clf, grid, cv=2, fit_params=dict(max_steps=1000, monitor_fn=monitor_fn))\n",
    "clf_grid = clf_grid.fit(X.values, y.values)\n",
    "#clfx.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_fn': <function __main__.my_model>,\n",
       " 'model_params': {'a1': 0.01, 'a2': 0.01, 'a3': 0.02}}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx = clf_grid.best_estimator_.monitors_['validate']\n",
    "mx.best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1373422b0>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x142f9cc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(clf_grid.best_estimator_.monitors_['loss'].values).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_variable_value('W2').T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??classifier.get_variable_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.590570e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>7.182880e-07</td>\n",
       "      <td>2.121569e-07</td>\n",
       "      <td>-5.213333e-07</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000886</td>\n",
       "      <td>0.399872</td>\n",
       "      <td>-1.533133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.584211e-03</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>4.702329e-04</td>\n",
       "      <td>-1.067056e-04</td>\n",
       "      <td>3.061176e-03</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>-1.532622</td>\n",
       "      <td>0.037584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.535604e-07</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>-9.332093e-07</td>\n",
       "      <td>-8.378229e-07</td>\n",
       "      <td>9.369740e-06</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>-1.532028</td>\n",
       "      <td>-1.309981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X0        X1            X2            X3            X4        X5  \\\n",
       "0  7.590570e-07  0.000007  7.182880e-07  2.121569e-07 -5.213333e-07 -0.000339   \n",
       "1 -2.584211e-03 -0.000005  4.702329e-04 -1.067056e-04  3.061176e-03  0.000252   \n",
       "2  3.535604e-07 -0.001238 -9.332093e-07 -8.378229e-07  9.369740e-06 -0.001001   \n",
       "\n",
       "         X6        X7        X8        X9  \n",
       "0 -0.000105 -0.000886  0.399872 -1.533133  \n",
       "1 -0.000497 -0.000726 -1.532622  0.037584  \n",
       "2 -0.000774 -0.000492 -1.532028 -1.309981  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts = np.hstack((classifier.get_variable_value('W1').T, classifier.get_variable_value('W2').T))\n",
    "pd.DataFrame(wts, columns=X.columns)#.T.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5lww9941/model.ckpt-1000-?????-of-00001.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    334\n",
       "2    333\n",
       "1    333\n",
       "dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.argmax(classifier.predict(X), axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: /var/folders/6g/kdqcxdms5dg0dr83wxn3ydjcsy9pxl/T/tmp5lww9941/model.ckpt-1000-?????-of-00001.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual         0      1      2\n",
       "predicted                     \n",
       "0          331.0    2.0    1.0\n",
       "1            1.0  331.0    1.0\n",
       "2            NaN    NaN  333.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = np.argmax(classifier.predict(X), axis=1)\n",
    "pd.DataFrame({'predicted':yp, 'actual': y.values}).groupby(['predicted', 'actual']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
