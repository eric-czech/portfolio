---
title: "Traumatic Brain Injury Study Results (pt. 3)"
author: "Eric Czech"
#output: ioslides_presentation
output: html_document
widescreen: yes
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
knit: (function(inputFile, encoding) { rmarkdown::render(
  inputFile, encoding=encoding, 
  output_file=file.path(dirname(inputFile), 'TBIResults03', '48hr', 'pres.doc.html')) })
---
  
```{r init, echo=FALSE, message=FALSE, warning=FALSE}
library(caret)
library(MASS)
library(pander)
library(plyr)
library(dplyr)
library(knitr)
library(glmulti)
library(dummies)
library(foreach)
library(plotly)
library(reshape2)
library(doMC)
library(xtable)
registerDoMC(4)

SEED <- 23823
set.seed(SEED)
source('~/repos/portfolio/demonstrative/R/pbto2/common.R')
source('~/repos/portfolio/demonstrative/R/pbto2/performance/cv_utils.R')
source('~/repos/portfolio/demonstrative/R/pbto2/selection/model_comparisons_lib.R')
select <- dplyr::select
MD_CACHE_DIR <- '/Users/eczech/data/pbto2/cache'

set.data.config('config3') # 48 hour source data
#set.data.config('config2') # 24 hour source data
#set.data.config('config6') # 72 hour source data
#set.data.config('config4') # 96 hour source data

##### Rendering Functions #####

add.p.stars <- function(p){
  sapply(p, function(x) {
    if (x <= .001) paste(x, '***')
    else if (x <= .01) paste(x, '**')
    else if (x <= .05) paste(x, '*')
    else if (x <= .1) paste(x, '.')
    else x
  })
}

print.coef.table <- function(coefs, n, outcome.desc, form=NULL){
  form <- if (is.null(form)) '' else paste0('<br>Formula="', form, '"')
  caption <- sprintf('3 Month Binary Outcome (%s, n=%s)%s', outcome.desc, n, form)
  data.frame(round(coefs, 3)) %>% 
    setNames(c('Coefficient', 'std', 'z', 'P.Value')) %>%
    add_rownames(var='Predictor') %>%
    mutate('Odds.Ratio'=round(exp(Coefficient), 3)) %>%
    select(-std, -z) %>% select(Predictor, Coefficient, Odds.Ratio, P.Value) %>%
    pandoc.table(caption=caption)
    #xtable(digits=3, caption = caption) %>%
    #print(type="html", caption.placement = "top", include.rownames=F, scalebox='0.75')
}

plot.ly <- function(p) { p %>% plotly::config(showLink = F, displayModeBar = F) }
```

```{r loading, echo=FALSE, cache=TRUE}
dsu <- get.wide.data(outcome.func=gos.to.binom, scale.vars=F, remove.na.flags=F)
dmu <- get.wide.data(outcome.func=gos.to.mort, scale.vars=F, remove.na.flags=F)
p <- c('age', 'sex', 'marshall', 'gcs')

models <- get.models(p)
all.vars <- models[['all.vars']]
models <- models[['models']]

# Calculate outcome frequencies
d.stat.freq <- dsu %>% mutate(gos=ifelse(gos==0, 'Bad', 'Good')) %>% 
  group_by(gos) %>% tally %>% data.frame
d.mort.freq <- dmu %>% mutate(gos=ifelse(gos==0, 'Dead', 'Alive')) %>% 
  group_by(gos) %>% tally %>% data.frame

# Calculate covariate frequencies
d.cov.dist <- dsu %>% select(uid, one_of(p)) %>% 
  mutate(age=cut(age, breaks=seq(0, 100, by=10), right=T)) %>%
  mutate_each(funs(factor), one_of(c('sex', 'marshall', 'gcs'))) %>% 
  melt(id.vars='uid') %>% group_by(variable, value) %>% summarise(count=n()) %>% 
  ungroup %>% mutate(pct=round(100*count/nrow(dsu), 2))

# Calculate gas/pressure distributions
d.var.n <- dsu %>% select(contains('is_na')) %>% melt(id.vars=NULL) %>% 
  group_by(variable) %>% summarise(ct=sum(value), n=n()) %>%
  mutate(variable=str_replace(variable, '_is_na', '')) %>%
  filter(variable %in% c('icp1', 'pao2', 'pbto2')) %>%
  mutate(N=n-ct, Total=n, Percent.Present=round(100*(n-ct)/n, 2)) %>%
  rename(Variable=variable) %>% select(-ct, -n) %>% data.frame
```

```{r linear_modeling, echo=FALSE}
## PbtO2 + Outcome (linear models)


f.glm.pbto2 <- get.form(models[['wcov_pbto2']])

d.glm.stat.pbto2 <- dsu %>% prep.df('pbto2')
m.glm.stat.pbto2 <- glm(f.glm.pbto2, data=d.glm.stat.pbto2, family='binomial')
r.glm.stat.pbto2 <- summary(m.glm.stat.pbto2)

d.glm.mort.pbto2 <- dmu %>% prep.df('pbto2')
m.glm.mort.pbto2 <- glm(f.glm.pbto2, data=d.glm.mort.pbto2, family='binomial')
r.glm.mort.pbto2 <- summary(m.glm.mort.pbto2)


f.glm.pbto2.int <- as.formula(sprintf('gos ~ pbto2_0_20*(%1$s) + pbto2_70_inf*(%1$s)', paste(p, collapse='+')))
# Results from glmulti pulled from disk (so they must be manually updated)
# * This is because of this problem with glmulti + knitr: 
#   http://stackoverflow.com/questions/3661500/why-cant-i-pass-a-dataset-to-a-function

# m.glmulti.stat.pbto2 <- glmulti(f.glm.pbto2.int, data=d.glm.stat.pbto2, 
#                                 family='binomial', crit = AICc, level=1, plotty=F, report=F)
# save(m.glmulti.stat.pbto2, file=file.path(MD_CACHE_DIR, 'm.glmulti.stat.pbto2.rda'))
# m.glmulti.mort.pbto2 <- glmulti(f.glm.pbto2.int, data=d.glm.mort.pbto2, 
#                                 family='binomial', crit = AICc, level=1, plotty=F, report=F)
# save(m.glmulti.mort.pbto2, file=file.path(MD_CACHE_DIR, 'm.glmulti.mort.pbto2.rda'))

load(file.path(MD_CACHE_DIR, 'm.glmulti.stat.pbto2.rda'))
load(file.path(MD_CACHE_DIR, 'm.glmulti.mort.pbto2.rda'))

r.glmulti.stat.pbto2 <- summary(m.glmulti.stat.pbto2@objects[[1]])
r.glmulti.mort.pbto2 <- summary(m.glmulti.mort.pbto2@objects[[1]])


# - Show coefficients and AIC from covariates + PbtO2 
# - Validation of known lower cutoff for pbto2
# - Explain significance of PbtO2
# - ask about validation of 20 for pbto2
# - ask about upper pbto2 cutoff
```

```{r resample_modeling, echo=FALSE}

##### Define Data #####

factor.good.bad <- function(gos) 
  factor(ifelse(gos==0, 'bad', 'good'), levels=c('good', 'bad'))

d.pbto2.pao2 <- dsu %>% prep.df(c('pbto2', 'pao2')) %>% mutate(gos=factor.good.bad(gos))
d.icp1.pbto2.pao2 <- dsu %>% prep.df(c('pbto2', 'pao2', 'icp1')) %>% mutate(gos=factor.good.bad(gos))

##### Define Model Formulas #####

f.pbto2.pao2 <- get.form(models[['wcov_pao2_pbto2']])
f.pbto2.pao2.int <- as.formula(sprintf(
  '%s + pbto2_0_20:pao2_0_300 + pbto2_70_inf:pao2_875_inf', 
  deparse(f.pbto2.pao2, width.cutoff = 100)
))
f.pbto2 <- get.form(models[['wcov_pbto2']])
f.pao2 <- get.form(models[['wcov_pao2']])
f.icp1.pbto2.pao2 <- get.form(models[['wcov_icp_pao2_pbto2']])
f.icp1.pbto2.pao2.int <- as.formula(sprintf(
  '%s + pbto2_0_20:pao2_0_300 + pbto2_70_inf:pao2_875_inf + icp1_20_inf:(%s)', 
  deparse(f.icp1.pbto2.pao2, width.cutoff = 100),
  'pbto2_0_20 + pao2_0_300 + pbto2_70_inf + pao2_875_inf'
))
f.icp1.pbto2 <- get.form(models[['wcov_icp_pbto2']])
f.icp1.pbto2.int <- as.formula(sprintf(
  '%s + icp1_20_inf:(pbto2_0_20 + pbto2_70_inf)', 
  deparse(f.icp1.pbto2, width.cutoff = 100)
))
f.icp1.pao2 <- get.form(models[['wcov_icp_pao2']])
f.icp1.pao2.int <- as.formula(sprintf(
  '%s + icp1_20_inf:(pao2_0_300 + pao2_875_inf)', 
  deparse(f.icp1.pbto2, width.cutoff = 100)
))

##### Define Training Routine #####

run.model.set <- function(form, data, metric, preproc=c('center', 'scale')){
  
  # Create Data Partition
  set.seed(SEED)
  #folds <- createMultiFolds(data$gos, k = 10, times = 8)
  folds <- createFolds(data$gos, k = length(data$gos), returnTrain=T)
  summary.func <- function(...) c(defaultSummary(...), twoClassSummary(...))
  trctl <- trainControl(index=folds, savePredictions=T, classProbs=T, summaryFunction=summary.func)
  
  # Fit each model
  train.model <- function(method, pre=preproc, ...){
    cat('Training model "', method, '" ...\n')
    set.seed(SEED)
    train(form, data=data, method=method, preProcess=pre, metric=metric, trControl=trctl, ...)
  }
  
  res <- list()
  res$glm <- train.model('glm')
  res$rpart <- train.model('rpart', tuneLength=25)
  res$gbm <- train.model('gbm', tuneLength=5)
  res$nnet <- train.model('nnet', tuneLength=5, maxit=1000)
  res$lda <- train.model('lda', tuneLength=15)
  res$knn <- train.model('knn', tuneLength=15)
  cat('Model training complete\n')
  list(models=res, folds=folds, form=form, n=nrow(data))
}


##### Get Performance Measures #####

target.metric <- 'Accuracy'

# Full set with PbtO2 + PaO2 (N=~262)
r.pbto2.pao2.all <- run.model.set(f.pbto2.pao2, d.pbto2.pao2, target.metric)
#r.pbto2.pao2.int.all <- run.model.set(f.pbto2.pao2.int, d.pbto2.pao2, target.metric)
r.pbto2.all <- run.model.set(f.pbto2, d.pbto2.pao2, target.metric)
r.pao2.all <- run.model.set(f.pao2, d.pbto2.pao2, target.metric)

# Reduced set with PbtO2 + PaO2 (N=~166)
r.pbto2.pao2.red <- run.model.set(f.pbto2.pao2, d.icp1.pbto2.pao2, target.metric)
#r.pbto2.pao2.int.red <- run.model.set(f.pbto2.pao2.int, d.icp1.pbto2.pao2, target.metric)
r.pbto2.red <- run.model.set(f.pbto2, d.icp1.pbto2.pao2, target.metric)
r.pao2.red <- run.model.set(f.pao2, d.icp1.pbto2.pao2, target.metric)

# Reduced set with PbtO2 + PaO2 (N=~166)
r.icp1.pbto2.pao2 <- run.model.set(f.icp1.pbto2.pao2, d.icp1.pbto2.pao2, target.metric)
r.icp1.pbto2 <- run.model.set(f.icp1.pbto2, d.icp1.pbto2.pao2, target.metric)
r.icp1.pao2 <- run.model.set(f.icp1.pao2, d.icp1.pbto2.pao2, target.metric)


plot.metric <- 'ROC'
extract.perf <- function(r) foreach(m=names(r), .combine=rbind) %do% {
  stats <- twoClassSummary(r[[m]]$pred, lev=levels(d.pbto2.pao2$gos))
  t(as.data.frame(stats)) %>% as.data.frame %>% mutate(model=m)
}
model.perf <- rbind(
  extract.perf(r.pbto2.pao2.red$models) %>% rename_(value=plot.metric) %>% mutate(dataset='pbto2.pao2'),
  extract.perf(r.pao2.red$models) %>% rename_(value=plot.metric) %>% mutate(dataset='pao2'),
  extract.perf(r.pbto2.red$models) %>% rename_(value=plot.metric) %>% mutate(dataset='pbto2')
)
  
n <- dplyr::n
model.perf %>% ggplot(aes(x=model, fill=dataset, y=value)) + 
  geom_bar(stat='identity', position='dodge')


model.perf %>%
  mutate(model=reorder(model, model.perf$value, FUN = mean)) %>%
  ggplot(aes(x=model, y=value, color=dataset)) + 
  geom_boxplot(width=.5, alpha=.5, position='dodge') +
  #geom_jitter(position = position_jitter(width=.5), alpha=.5) + 
  theme_bw() + coord_flip()


```

<br><br>

<center><h1>TBI Study Results</h1></center>
<hr>

## Contents

- **Section 1**: [Data Overview and Assumptions](#id1)
- **Section 2**: [Findings for PbtO2 + Outcome](#id2) (where "outcome" means gos of 1,2,3 vs 4,5)
- **Section 3**: [Findings for PbtO2 + Mortality](#id3) (where "mortality" means gos of 1 vs 2,3,4,5)
- **Section 4**: [Findings for PbtO2 vs PaO2 and ICP](#id4)

<hr>
<center><h2><a id="id1">1. Data Overview and Assumptions</a></center></h2></center>
<hr>

### Assumptions

All samples rejected if any of the following were not present:

  - GOS Outcome (3 OR 6 month)
  - Age, Gender, GCS, Marshall Score
  - At least 8 PbtO2 measurements

Only complete cases were considered for models using multiple gas measurements.  In other words, these results do not include imputations of predictors (though imputations were tried and showed no difference in results).

If a 3-month GOS outcome was not present, the 6 month outcome was used instead.

### Sample Size by Variable

A count of the number of samples present for each variable to be modeled:

```{r, echo=FALSE}
d.var.n
```

### Data Distributions

### Covariate Histograms

All of the following are from a population of size: 
```{r, echo=F} 
cat(paste('N =', nrow(dsu)))
```

```{r, echo=FALSE, warning=FALSE, fig.width=5, fig.height=5, fig.align='center'}
ggplot(d.cov.dist, aes(x=value, y=count)) + geom_bar(stat='identity') + 
  facet_wrap(~variable, nrow=2, scales='free') + theme_bw() 
```

Raw data for the above:

```{r, echo=FALSE}
variables <- unique(d.cov.dist$variable)
lapply(variables, function(x){
  subset(d.cov.dist, variable==x) %>% select(-variable) %>%
    rename(Value=value, Frequency=count, Percentage=pct) %>%
    data.frame
}) %>% setNames(paste('Distribution Summary for Variable:', variables))
```

### Gas and Pressure Distributions

Distributions of gas and pressure measurements across all applicable samples:

```{r, echo=FALSE, fig.width=8, fig.height=5, fig.align='center'}
dsu %>% select(uid, starts_with('pao2'), starts_with('icp1'), starts_with('pbto2')) %>%
  select(-ends_with('is_na')) %>% melt(id.vars='uid') %>% 
  ggplot(aes(x=value)) + geom_histogram(binwidth=.05) + 
  facet_wrap(~variable, nrow=2, scales='free') + theme_bw()
```

Note that for each variable above, a single patient's value for that variable was computed as the fraction of time for which the measurements were above or below are particular threshold.  Those thresholds are in the names of the variables where a name like ```pao2_875_inf``` indicates the fraction of time (over all their measurements) the patient had a PaO2 value measured as greater than 875.

<hr>
<center><h1><a id="id2">2. PbtO2 + Outcome</a></center></h1></center>
<hr>

### Results

- **Result 1**: PbtO2 is an important predictor of outcomes
- **Result 2**: PbtO2 is retained in stepwise model selection
- **Result 3**: PbtO2 thresholds are optimal when set at 20 and ~70

#### Result 1

PbtO2 is a significant predictor of outcomes after controlling for age, gender, marshall, and gcs.

Here are results from a linear, logistic model showing this:

```{r, echo=FALSE, results='asis'}
print.coef.table(coef(r.glm.stat.pbto2), nrow(d.glm.stat.pbto2), 'Good vs Bad', deparse(f.glm.stat.pbto2))
```

#### Result 2

Stepwise model selection (using exhaustive AIC search) for the above  again shows that PbtO2 is an important predictor.  This shown by the fact that PbtO2 is retained the best model.

Best model chosen after starting with the model in **Result 1** above:

```{r, echo=FALSE, results='asis'}
print.coef.table(coef(r.glmulti.stat.pbto2), nrow(d.glm.stat.pbto2), 
                 'Good vs Bad', deparse(r.glmulti.stat.pbto2$terms))
```

Note that the variables ```sex``` and ```pbto2_70_inf``` were excluded from the best model.

#### Result 3

In the models above the lowest and highest values considered to be "safe" for PbtO2 were 20 and 70 respectively.  The lower setting for these thresholds, 20, was set based on prior knowledge.  The upper setting, however, was determined using a model designed to find these optimal thresholds.  This approach was designed to determine which of the following are true:

1. There is **no** threshold in PbtO2 values that best predicts outcomes
2. There is **one** threshold in PbtO2 values for which time spent above and below that value best predict outcomes
3. There are **two** thresholds in PbtO2 values that best predict outcomes

The results from applying this technique shows two things:

1. Time spent (by patients) with PbtO2 values below 15-20 are highly correlated with poor outcomes
2. Time spent with PbtO2 values **above** 70-100 are also correlated with poor outcomes (but less so)

Item #1 above seems to be common knowledge while item #2 is not.  To better illustrate why #2 is true, here is a plot of the PbtO2 values for every single patient that ever had a value above 100 and their corresponding GOS outcome:

<center>
<img src="/Users/eczech/repos/portfolio/demonstrative/R/pbto2/images/high_pbto2.png" width="800px" height="400px"/><br>
</center>

Note that all but one patient had a GOS score of 3 or lower (which are all poor outcomes).


<hr>
<center><h2><a id="id3">3. PbtO2 + Mortality</a></center></h2></center>
<hr>

#### Results

PbtO2 is **not** a signficant predictor of mortality.

Here are the linear modeling coefficient results applied in exactly the same way as with good/bad outcomes, but with a new outcome defined as ```outcome = 0 if GOS = 1, 1 otherwise```:

Model coefficients:

```{r, echo=FALSE, results='asis'}
print.coef.table(coef(r.glmulti.mort.pbto2), nrow(d.glm.mort.pbto2), 
                 'Alive vs Dead', deparse(r.glmulti.mort.pbto2))
```

Only age and GCS are significant in this case.

Similarly, PbtO2 is also lost in stepwise model selection where the below shows the best model chosen from all combinations of predictors in the model above:

```{r, echo=FALSE, results='asis'}
print.coef.table(coef(r.glmulti.pbto2.mort), nrow(d.glm.mort.pbto2), 'Alive vs Dead', deparse(r.glmulti.pbto2.mort$terms))
```

Again, only age and GCS are significant while PbtO2, sex, and marshall scores are all lost.

<hr>
<center><h1><a id="id4">4. Findings for PbtO2 vs PaO2 and ICP</a></center></h1></center>
<hr>

### Results

- **Result 1**: PbtO2 vs PaO2 (all samples)
- **Result 2**: PbtO2 vs PaO2 (samples w/ ICP)
- **Result 3**: PbtO2 vs PaO2 vs ICP

#### Result 1

The 


- Show glm results from the following:
  - PaO2 + Pbto2 all samples
- PaO2 + Pbto2 only samples w/ icp
- PaO2 + Pbto2 + ICP




## Findings

- PbtO2 is a significant predictor of outcomes after controlling for age, gender, marshall, and gcs 
- 
- Show coefficients and AIC from covariates + PbtO2 
- Validation of known lower cutoff for pbto2
- Explain significance of PbtO2
- ask about validation of 20 for pbto2
- ask about upper pbto2 cutoff

## PbtO2 + Outcome {.smaller}

Summary of findings:
  


```{r}
#m.glm.stat.pbto2
```


## PbtO2 + Outcome (exhaustive models)

- Show that PbtO2 is not lost in exhaustive AIC search

## PbtO2 + Outcome (flexible models)

- Show fancy model and threshold chosen for PbtO2 
- Mention what David said about high PbtO2
- Show CV performance (difference of AUC distributions)

# Part 2: PbtO2 + Mortality

- Same as part 1 but with different outcome

# Part 3: PbtO2 vs PaO2

## Linear Models

- Show glm results from the following:
  - PaO2 + Pbto2 all samples
- PaO2 + Pbto2 only samples w/ icp
- PaO2 + Pbto2 + ICP

## ROC Analysis

- Show ROC curves and AUC numbers for models containing all covariates + PbtO2 vs the same w/ PaO2
- Also show the same as above with ICP


