---
title: "Shrinkage/Pooling/Regularization Example"
output: html_document
---

```{r, results='hide', message=F, warning=F, echo=F}
library(dplyr)
library(plotly)
library(lme4)
```

Load some libraries:

```{r}
library(dplyr)
library(plotly)
library(lme4)
```

Take a look at Scott's example data:

```{r}
# Actual sample data sample for group (from Scott) 
d <- read.csv('/Users/eczech/data/meetups/musc_r_group/sampledata.csv')
d %>% plot_ly(x=acuity, y=or_time_obs, color=factor(doctor), type='scatter', mode='markers')
```

<br><br><br>
Now generate data similar to the above, but add more samples:

```{r}
# Simulated data with more samples similar to the above
n <- 25

# This parameter controls the "strength" of the pooling.  Decreasing it means less pooling/shrinkage
# occurs and the averages end up being closer to what they are when calculated directly
weight.exp <- .75 

set.seed(1)
d <- rbind(
  # Generate 3 "normal" doctors and their acuity / OR time numbers
  data.frame(doctor=1, acuity=rnorm(n, 3, .5), or_time_obs=rnorm(n, 75, 3)),
  data.frame(doctor=2, acuity=rnorm(n, 4.2, .5), or_time_obs=rnorm(n, 72, 3)),
  data.frame(doctor=3, acuity=rnorm(n, 3.2, .5), or_time_obs=rnorm(n, 82, 3)),
  
  # Generate one oddball doctor with only 2, atypical measurements
  data.frame(doctor=4, acuity=c(6.8, 5.1), or_time_obs=c(95, 82))
) %>% 
  mutate(doctor=factor(paste('Doctor', doctor))) %>%
  group_by(doctor) %>% mutate(weight=n()^(weight.exp)) %>% ungroup %>%
  mutate(weight=weight/n())

# Scatter plot function showing actual data and means for each doctor
plot.data <- function(d, d.mean){
  d %>%
    plot_ly(
      x=acuity, y=or_time_obs, color=doctor, type='scatter', mode='markers', 
      marker=list(size=5), legendgroup='Actual'
    ) %>% add_trace(
      data=d.mean, x=acuity, y=or_time_obs, color=doctor, type='scatter', mode='markers', 
      marker=list(size=15), legendgroup='Means'
    )  
}

# Plot the original simulated data and the means for each doctors stats
d.mean <- d %>% group_by(doctor) %>% summarise_each(funs(mean))
plot.data(d, d.mean)
```

<br><br><br>
Now try to do something to make a better estimate for the average for Doctor 4.

One way to do this is by creating a "varying-intercepts"" models that more directly models the average acuity
and or_time_obs, but does so by "pooling" information across all the doctors.  If a doctor has a lot of samples, this pooling (aka "shrinkage") has little effect, but if they have fewer samples it has a stronger effect.

Fit a model for the averages with pooling and see how that effects the estimates:

```{r}

# Note that if "lm" (i.e. fixed-effects regression) was used below instead of "lmer" 
# (i.e. "random/mixed effects regression") then the results would be exactly equivalent
# to calculting the mean of each value by doctor directly. 
m.ac <- lmer(acuity ~ (1|doctor), d, weights=d$weight)
m.or <- lmer(or_time_obs ~ (1|doctor), d, weights=d$weight)

# Use the model to get the predicted average acuity and or_time_obs for each doctor
d.doc <- data.frame(doctor=unique(d$doctor))
d.mean.reg <- data.frame(
  doctor=d.doc$doctor,
  acuity=predict(m.ac, d.doc),
  or_time_obs=predict(m.or, d.doc)
)

# Plot the data with the new, shrunken average values
plot.data(d, d.mean.reg)
```
